{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SN backpropagation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "52cz_d6IzUW-",
        "colab_type": "code",
        "outputId": "3dc16b5d-741d-4e02-d463-786b13a9e3b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "! [ ! -z \"$COLAB_GPU\" ] && pip install torch scikit-learn==0.20.* skorch\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "import tensorflow\n",
        "# Loading the machine learning packages \n",
        "from xgboost import XGBClassifier\n",
        "import xgboost as xgb\n",
        "from sklearn.ensemble import AdaBoostClassifier, RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV \n",
        "from sklearn.metrics import mean_absolute_error, accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import preprocessing \n",
        "from sklearn.metrics import roc_curve\n",
        "# from tensorflow.examples.tutorials.mnist import input_data\n",
        "from sklearn import datasets, svm, metrics\n",
        "# from sklearn.datasets import fetch_mldata\n",
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "# importing one hot encoder from sklearn \n",
        "from sklearn.preprocessing import OneHotEncoder "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.5.0+cu101)\n",
            "Requirement already satisfied: scikit-learn==0.20.* in /usr/local/lib/python3.6/dist-packages (0.20.4)\n",
            "Requirement already satisfied: skorch in /usr/local/lib/python3.6/dist-packages (0.8.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.4)\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.20.*) (1.4.1)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.6/dist-packages (from skorch) (4.41.1)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from skorch) (0.8.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYNp4poboKDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgwBFo_bz0OR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing the Mnist data\n",
        "\n",
        "# mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
        "mnist = fetch_openml('mnist_784', cache=False)\n",
        "\n",
        "\n",
        "# X = X[0:100,:]\n",
        "# y = y[]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMnRtCq1z0ES",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = mnist.data.astype('float32')\n",
        "y = mnist.target.astype('int64')\n",
        "##selecting a small sample out of 70k to speed up coding and fix bugs\n",
        "samples = 100\n",
        "X = X[0:samples][:]\n",
        "y = y[0:samples]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmiRkR1HpbXY",
        "colab_type": "code",
        "outputId": "9ee76014-8aa2-4ce3-c8eb-1e75cb5d0b72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "i = 17\n",
        "plt.imshow(X[i][:].reshape(28,28),cmap='gray')\n",
        "print(y[i])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoY7N3Ncqb3g",
        "colab_type": "code",
        "outputId": "0605bcf8-bc2c-49ad-db58-2d432417b049",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "y = y.reshape(-1,1)\n",
        "onehotencoder = OneHotEncoder() \n",
        "y_onehot = onehotencoder.fit_transform(y).toarray() \n",
        "eps = 43\n",
        "X = X*eps/np.max(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_onehot, test_size=0.25, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GS_ppcb9tuC0",
        "colab_type": "text"
      },
      "source": [
        "Preprocessing done X train has training set while X_test has the validation det. Y is in one hot encoding. X's pixels are scaled from 0-1. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1TAqRufsX4V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#user defined inputs:\n",
        "t_mp =0.02\n",
        "t_ref = 0.001\n",
        "alpha = 7\n",
        "n_w = 0.03\n",
        "n_th = 0.1*n_w\n",
        "beta = 10\n",
        "l = 0.03\n",
        "rho = 0.0002\n",
        "\n",
        "n_in= 784#must be 28*28\n",
        "n_hidden = 200#variable\n",
        "n_out= 10\n",
        "epochs = 100\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bQfPWm3BafU",
        "colab_type": "text"
      },
      "source": [
        "Here m represents the no of synapse. As the it is a fully connected network nno of synapse in ith layer is equal to no of node in i-1 layer. In input layer hash one synapse only.\n",
        "\n",
        "W[i][j] represent the weight of ith neuron of a layer connected to jth neuron of the next layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qdu1H9q9iLZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m_in = 1\n",
        "m_hidden = n_in\n",
        "m_out = n_hidden\n",
        "\n",
        "w_in = [random.uniform(-1*math.sqrt(3/m_in),1*math.sqrt(3/m_in)) for i in range(n_in)]\n",
        "w_hidden = [[random.uniform(-1*math.sqrt(3/m_hidden),1*math.sqrt(3/m_hidden)) for i in range (m_hidden)] for j in range(n_hidden)]\n",
        "w_out = [[random.uniform(-1*math.sqrt(3/m_out),1*math.sqrt(3/m_out)) for i in range(m_out)] for j in range(n_out)]\n",
        "\n",
        "vth_in = [alpha*math.sqrt(3/m_in) for i in range(n_in)]\n",
        "vth_hidden = [alpha*math.sqrt(3/m_hidden) for i in range(n_hidden)]\n",
        "vth_out = [alpha*math.sqrt(3/m_out) for i in range(n_out)]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sMVsHTJ-tBc",
        "colab_type": "code",
        "outputId": "bb9181d5-707c-4153-c131-c0fc6da5a18a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(np.max(w_hidden))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.06185682776694027\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5j-27qHDEDu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this fundtion takes in the mean and generates the no of spikes in time ms second.\n",
        "# gives the index value when it spikes. if spikes = [10,20,40]\n",
        "\n",
        "def gen_spike(mean,time):#time is in ms\n",
        "  A = [random.uniform(0,1) for i in range(time)]\n",
        "  threshold = mean/time\n",
        "  spikes = []\n",
        "  count = 0 \n",
        "  for i in range(len(A)):\n",
        "    if A[i] < threshold:\n",
        "      spikes.append(i)\n",
        "      # count= count +1\n",
        "  # print(len(spikes))\n",
        "  return spikes\n",
        "# stimulus =A[A<threshold];\n",
        "def initialize():\n",
        "  m_in = 1\n",
        "  m_hidden = n_in\n",
        "  m_out = n_hidden\n",
        "\n",
        "  w_in = [random.uniform(-1*math.sqrt(3/m_in),1*math.sqrt(3/m_in)) for i in range(n_in)]\n",
        "  w_hidden = [[random.uniform(-1*math.sqrt(3/m_hidden),1*math.sqrt(3/m_hidden)) for i in range (m_hidden)] for j in range(n_hidden)]\n",
        "  w_out = [[random.uniform(-1*math.sqrt(3/m_out),1*math.sqrt(3/m_out)) for i in range(m_out)] for j in range(n_out)]\n",
        "\n",
        "  vth_in = [alpha*math.sqrt(3/m_in) for i in range(n_in)]\n",
        "  vth_hidden = [alpha*math.sqrt(3/m_hidden) for i in range(n_hidden)]\n",
        "  vth_out = [alpha*math.sqrt(3/m_out) for i in range(n_out)]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCDnpsP1TNlE",
        "colab_type": "code",
        "outputId": "18facd8d-773b-49b8-c745-cf12dbabee97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "initialize()\n",
        "time = 1000#1 s for each image\n",
        "# trianing =1\n",
        "training = 25\n",
        "for img in range(training):\n",
        "  inputs = []\n",
        "  for i in X_train[img]:\n",
        "    inputs.append(gen_spike(i,time))# inputs tell me which neurons recieve spike.inputs[k] has input spike times of kth input neuron\n",
        "  # print(len(inputs),spike_time)\n",
        "  spike_time = [ [] for i in range(time+1)]\n",
        "  for i in range(len(inputs)):\n",
        "    for j in inputs[i]:\n",
        "      # print(j)\n",
        "      spike_time[j].append(i)\n",
        "\n",
        "  in_hidden = [[[] for i in range(m_hidden)] for j in range(n_hidden)]\n",
        "  #####layer 1\n",
        "\n",
        "  hid_ispikes = [[] for i in range(time+1)]\n",
        "  a_in = [[] for i in range(n_in)]#ouput spike of input layer. a_in[j] has spike time of jth neuron\n",
        "\n",
        "  nin_vmp_t=  [[0,0] for i in range(n_in)]# collects infor mation of jth neuron after last inputspike. vmp and time\n",
        "  pre_spike = 0# time when last ouputspike occured of this layer\n",
        "  for i in range(1,time+1):#1 ms interval \n",
        "    # for i in range(n_in):\n",
        "    next_spike = pre_spike \n",
        "    has_spiked = {}\n",
        "    for j in spike_time[i]:\n",
        "      if j>=len(nin_vmp_t):\n",
        "        print(img,spike_time)\n",
        "      # if last_v [j] == []:# if jth no input spike before:\n",
        "      # #   v_pre = 0\n",
        "      # #   t_pre = 0\n",
        "      # # else:\n",
        "      # #   v_pre = last_v[j][0]\n",
        "      # #   t_pre = last_v[j][1]\n",
        "      delta_t = (pre_spike - i)/1000\n",
        "      # if delta_t < t_ref :\n",
        "      w_dyn = min((delta_t/t_ref)**2,1)\n",
        "      nin_vmp_t[j][0] = nin_vmp_t[j][0]*math.exp( ( i - nin_vmp_t[j][1]) / (1000*t_mp))  + w_dyn*w_in[j]\n",
        "      nin_vmp_t[j][1] = i\n",
        "      if nin_vmp_t[j][0] > vth_in[j] and j not in has_spiked:\n",
        "        nin_vmp_t[j][0] = 0\n",
        "        next_spike = i\n",
        "        a_in[j].append(i)\n",
        "        hid_ispikes[i].append(j)\n",
        "        has_spiked[j] =1\n",
        "    pre_spike = next_spike\n",
        "\n",
        "  ###layer 2 now. it has input spike in hid_spike. hid_ispike[i] has neurons of inputlayer that spiked at ith ms.\n",
        "  ##a_in[j] has the time when jth neuron spiked\n",
        "  a_hidden = [[] for i in range(n_hidden)]#ouput spike of hidden layer\n",
        "  out_ispikes = [[] for i in range(time+1)]\n",
        "\n",
        "  pre_spike = 0\n",
        "  hid_vmp_t=  [[0,0] for i in range(n_hidden)]\n",
        "  for i in range(1,time+1):\n",
        "    next_spike = pre_spike\n",
        "    has_spiked = {}\n",
        "    for ispike in hid_ispikes[i]:\n",
        "      for j in range(n_hidden):\n",
        "        #time instant:::::i\n",
        "        #inputspike from ispike\n",
        "        # curr neuron ::::j\n",
        "        delta_t = (pre_spike - i)/1000\n",
        "        w_dyn = min((delta_t/t_ref)**2,1)\n",
        "        hid_vmp_t[j][0] = hid_vmp_t[j][0]*math.exp( ( i - hid_vmp_t[j][1]) / (1000*t_mp))  + w_dyn*w_hidden[j][ispike]\n",
        "        hid_vmp_t[j][1] = i\n",
        "        if hid_vmp_t[j][1]> vth_hidden[j] and j not in has_spiked:\n",
        "          hid_vmp_t[j][0] = 0\n",
        "          next_spike = i\n",
        "          a_hidden[j].append(i)\n",
        "          out_ispikes[i].append(j)\n",
        "          has_spiked[j]= 1\n",
        "    pre_spike = next_spike\n",
        "  \n",
        "  ###output now. it has input spike in out_ispike. out_ispike[i] has neurons of inputlayer that spiked at ith ms.\n",
        "  ##a_in[j] has the time when jth neuron spiked\n",
        "  a_out = [[] for i in range(n_out)]#ouput spike of ouput layer\n",
        "  pre_spike = 0\n",
        "  out_vmp_t=  [[0,0] for i in range(n_out)]\n",
        "  for i in range(1,time+1):\n",
        "    next_spike = pre_spike\n",
        "    has_spiked = {}\n",
        "    for ispike in out_ispikes[i]:\n",
        "      for j in range(n_out):\n",
        "        #time instant:::::i\n",
        "        #inputspike from ispike\n",
        "        # curr neuron ::::j\n",
        "        delta_t = (pre_spike - i)/1000 \n",
        "        w_dyn = min((delta_t/t_ref)**2,1)\n",
        "        out_vmp_t[j][0] = out_vmp_t[j][0]*math.exp( ( i - out_vmp_t[j][1]) / (1000*t_mp))  + w_dyn*w_out[j][ispike]\n",
        "        out_vmp_t[j][1] = i\n",
        "        if out_vmp_t[j][1]> vth_out[j] and j not in has_spiked  :\n",
        "          out_vmp_t[j][0] = 0\n",
        "          next_spike = i\n",
        "          a_out[j].append(i)\n",
        "          has_spiked[j] =1\n",
        "\n",
        "    pre_spike = next_spike\n",
        "  print(\"done forward prop image\",img)\n",
        "    ###############################################################################################################################\n",
        "  ####backward propagation.\n",
        "  o = [ len(o_spike) for o_spike in a_out]\n",
        "  max_spike = np.max(o)\n",
        "  o = o/max_spike\n",
        "  nze = 0\n",
        "  predicted = np.argmax(o)\n",
        "  print(\"predicted: \",predicted,\" label: \",np.argmax(y_train[img]) )\n",
        "\n",
        "  for i in range(len(o)):\n",
        "    if o[i]-y[i]!= 0:\n",
        "      nze = nze + 1\n",
        "  ##classification\n",
        "  # label = max()\n",
        "\n",
        "  g_out = [1/vth_out[i] for i in range(n_out)]\n",
        "  g_hidden = [1/vth_hidden[i] for i in range(n_hidden)]\n",
        "  g_in = [1/vth_in[i] for i in range(n_in)]\n",
        "\n",
        "  nact_in = 0#denotes the number of nodes that spiked at any time at the layer\n",
        "  nact_hidden = 0\n",
        "  nact_out = 0\n",
        "  for i in a_in:\n",
        "    if len(i) >0:\n",
        "      nact_in=nact_in+1\n",
        "  for i in a_hidden:\n",
        "    if len(i) >0:\n",
        "      nact_hidden=nact_hidden+1\n",
        "  for i in a_out:\n",
        "    if len(i) >0:\n",
        "      nact_out=nact_out+1  \n",
        "\n",
        "  gavg_in = math.sqrt(sum([g_in[i]*g_in[i] for i in range(n_in) ]) / nact_in)\n",
        "  gavg_hidden = math.sqrt(sum([g_hidden[i]*g_hidden[i] for i in range(n_hidden) ]) / nact_hidden)\n",
        "  gavg_out = math.sqrt(sum([g_out[i]*g_out[i] for i in range(n_out) ]) / nact_out)\n",
        "  ##error calculation\n",
        "\n",
        "  #output layer\n",
        "  error_out = [(o[i] - y_train[img][i])/nze for i in range(n_out)]\n",
        "  loss = sum(error_out[i]*error_out[i] for i in range(n_out))\n",
        "  print(\"loss: \",loss)\n",
        "\n",
        "  #hidden layer\n",
        "  error_hidden = [ 0 for i in range(n_hidden)]\n",
        "  for i in range(n_hidden):\n",
        "    pre_fac = (g_hidden[i]/gavg_hidden) * math.sqrt(n_hidden/nact_hidden)\n",
        "    temp = 0.0\n",
        "    for j in range(n_out):\n",
        "      temp+=(error_out[j] * w_out[j][i])\n",
        "    error_hidden[i] =pre_fac* temp\n",
        "\n",
        "  #inpulayer\n",
        "  error_in = [0 for i in range(n_in)]\n",
        "  for i in range(n_in):\n",
        "    pre_fac = (g_in[i]/gavg_in) * math.sqrt(n_in/nact_in)\n",
        "    temp = 0.0\n",
        "    for j in range(n_hidden):\n",
        "      temp+= (error_hidden[j] * w_hidden[j][i])\n",
        "    error_in[i] = pre_fac* temp\n",
        "\n",
        "  ###Weight and threshold updation\n",
        "  n_w_in = [0 for i in range(n_in)]\n",
        "  n_w_hidden = [[0 for i in range (m_hidden)] for j in range(n_hidden)]\n",
        "  n_w_out = [[ 0 for i in range(m_out)] for j in range(n_out)]\n",
        "\n",
        "  #avering of input signals of every neuron\n",
        "  for i in range(n_in):\n",
        "    a_in[i] = len(a_in[i])\n",
        "  dum = max(a_in)\n",
        "  a_in = [a_in[i]/dum for i in range((n_in))]\n",
        "\n",
        "  for i in range(n_hidden):\n",
        "    a_hidden[i] = len(a_hidden[i])\n",
        "  dum = max(a_hidden)\n",
        "  a_hidden = [a_hidden[i]/dum for i in range((n_hidden))]\n",
        "\n",
        "  for i in range(n_out):\n",
        "    a_out[i] = len(a_out[i])\n",
        "  dum = max(a_out)\n",
        "  a_out = [a_out[i]/dum for i in range((n_out))]\n",
        "\n",
        "\n",
        "  for i in range(n_in):\n",
        "    inputs[i] = len(inputs[i])\n",
        "  dum = max(inputs)\n",
        "  inputs = [inputs[i]/dum for i in range((n_in))]\n",
        "\n",
        "  #output layer updation\n",
        "\n",
        "  for i in range(n_out):\n",
        "    req_fac = beta*l*math.exp(beta * sum([w_out[i][j]* w_out[i][j] - 1 for j in range(n_hidden)  ]))\n",
        "    for j in range(n_hidden):\n",
        "      n_w_out[i][j] = w_out[i][j] - n_w*(math.sqrt(n_out/nact_hidden) *error_out[i] * a_hidden[j]  + req_fac*w_out[i][j])\n",
        "      # print(\"out\",n_w_out[i][j] - w_out[i][j])\n",
        "    vth_out[i] = vth_out[i] - n_th* math.sqrt(n_out/(n_hidden*nact_hidden)) *error_out[i]*a_out[i]\n",
        "\n",
        "  #hidden layer weight updation\n",
        "\n",
        "  for i in range(n_hidden):\n",
        "    req_fac = beta*l*math.exp(beta * sum([w_hidden[i][j]* w_hidden[i][j] - 1 for j in range(n_in)  ]))\n",
        "    for j in range(n_in):\n",
        "      n_w_hidden[i][j] = w_hidden[i][j] - n_w*(math.sqrt(n_hidden/nact_in) *error_hidden[i] * a_in[j]  + req_fac*w_hidden[i][j])\n",
        "      # print(\"hidden\",n_w_hidden[i][j] - w_hidden[i][j])\n",
        "    vth_hidden[i] = vth_hidden[i] - n_th* math.sqrt(n_hidden/(n_in*nact_in)) *error_hidden[i]*a_hidden[i]\n",
        "\n",
        "  #inputlayer weight updation\n",
        "  for i in range(n_in):\n",
        "    req_fac = beta*l*math.exp(beta *( w_in[i]*w_in[i] -1))\n",
        "    # print(req_fac,\"in\")\n",
        "    # for j in range(n_in):\n",
        "    n_w_in[i] = w_in[i] - n_w*(1 *error_in[i] * inputs[i]+ req_fac*w_in[i])\n",
        "    vth_in[i] = vth_in[i] - n_th* math.sqrt(n_in) * error_in[i] * a_in[i]\n",
        "    # print(\"in\",n_w_in[i] - w_in[i])\n",
        "  # print(w_in-n_w_in)\n",
        "  # for i in range(n_in):\n",
        "  #   print(w_in[i]-n_w_in[i])\n",
        "  w_in = n_w_in\n",
        "  w_hidden = n_w_hidden\n",
        "  w_out = n_w_out\n",
        "  print(\"done backward prop image\",img)\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done forward prop image 0\n",
            "predicted:  0  label:  7\n",
            "loss:  0.18367346938775508\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "OverflowError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-142-31ad4698993e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    207\u001b[0m   \u001b[0;31m#inputlayer weight updation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m     \u001b[0mreq_fac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mw_in\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mw_in\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m     \u001b[0;31m# print(req_fac,\"in\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;31m# for j in range(n_in):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOverflowError\u001b[0m: math range error"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSY4NC9qcjK-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfI-xNfoRrK_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(inputs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Bm-nLqje3sP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print((w_hidden))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XP62rzl3xzkS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVBZyImWK1BR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZKldaq4egMx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(hid_ispikes)\n",
        "# print(out_ispikes)\n",
        "print(len(a_out[2]))\n",
        "print(a_out)\n",
        "print(np.max(spike_time))\n",
        "print(spike_time)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}