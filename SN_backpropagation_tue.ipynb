{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SN backpropagation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "52cz_d6IzUW-",
        "colab_type": "code",
        "outputId": "1f5f4939-8372-40e1-a3c0-40b4bc1b5583",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "! [ ! -z \"$COLAB_GPU\" ] && pip install torch scikit-learn==0.20.* skorch\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "import tensorflow\n",
        "# Loading the machine learning packages \n",
        "from xgboost import XGBClassifier\n",
        "import xgboost as xgb\n",
        "from sklearn.ensemble import AdaBoostClassifier, RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV \n",
        "from sklearn.metrics import mean_absolute_error, accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import preprocessing \n",
        "from sklearn.metrics import roc_curve\n",
        "# from tensorflow.examples.tutorials.mnist import input_data\n",
        "from sklearn import datasets, svm, metrics\n",
        "# from sklearn.datasets import fetch_mldata\n",
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "# importing one hot encoder from sklearn \n",
        "from sklearn.preprocessing import OneHotEncoder "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.5.0+cu101)\n",
            "Collecting scikit-learn==0.20.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/5b/5da31a6572dc6b7b2846a7cfcbe2e060a0e6af0e1059a6516965e40371b7/scikit_learn-0.20.4-cp36-cp36m-manylinux1_x86_64.whl (5.4MB)\n",
            "\u001b[K     |████████████████████████████████| 5.4MB 2.5MB/s \n",
            "\u001b[?25hCollecting skorch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/21/4936b881b33de285faa0b36209afe4f9724a0875b2225abdc63b23d384a3/skorch-0.8.0-py3-none-any.whl (113kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 45.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.20.*) (1.4.1)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.6/dist-packages (from skorch) (4.41.1)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from skorch) (0.8.7)\n",
            "Installing collected packages: scikit-learn, skorch\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed scikit-learn-0.20.4 skorch-0.8.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYNp4poboKDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgwBFo_bz0OR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing the Mnist data\n",
        "\n",
        "# mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
        "mnist = fetch_openml('mnist_784', cache=False)\n",
        "\n",
        "\n",
        "# X = X[0:100,:]\n",
        "# y = y[]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMnRtCq1z0ES",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = mnist.data.astype('float32')\n",
        "y = mnist.target.astype('int64')\n",
        "##selecting a small sample out of 70k to speed up coding and fix bugs\n",
        "samples = 100\n",
        "X = X[0:samples][:]\n",
        "y = y[0:samples]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmiRkR1HpbXY",
        "colab_type": "code",
        "outputId": "0b7236e6-f23a-4ae3-9541-3780356f75f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "i = 17\n",
        "plt.imshow(X[i][:].reshape(28,28),cmap='gray')\n",
        "print(y[i])\n",
        "plt.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAN8UlEQVR4nO3da6xV9ZnH8d9vGImGNgQHQbCinaovjMnQkegkygQ1NI43qJqmvJhQh8xpYo1tMjFD8FJ0YkImtMRbMKdgOB07kiZ4wUuGoqk6fWHjkaAiDNUxhyhBQCHBmkhHeebFWcec4tn/fdz3w/P9JCd77/XstdaTHX6s217774gQgBPfX3S7AQCdQdiBJAg7kARhB5Ig7EASf9nJldnm1D/QZhHhsaY3tWW3faXt3bbfsb28mWUBaC83ep3d9iRJf5C0UNL7kl6VtCQidhbmYcsOtFk7tuwXSXonIt6NiD9J2ihpURPLA9BGzYT9DEnvjXr9fjXtz9jusz1oe7CJdQFoUttP0EVEv6R+id14oJua2bLvlXTmqNffqKYB6EHNhP1VSefa/qbtyZK+L2lza9oC0GoN78ZHxGe2b5G0RdIkSY9ExFst6wxASzV86a2hlXHMDrRdW75UA2DiIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiCJhodsBrptypQpxfqLL75YszZ79uzivJdcckmxPjQ0VKz3oqbCbntI0seSPpf0WUTMa0VTAFqvFVv2yyLiwxYsB0AbccwOJNFs2EPSb2y/ZrtvrDfY7rM9aHuwyXUBaEKzu/GXRsRe2zMkbbX9PxHx8ug3RES/pH5Jsh1Nrg9Ag5raskfE3urxgKQnJF3UiqYAtF7DYbc9xfbXR55L+o6kHa1qDEBrNbMbP1PSE7ZHlvOfEfFfLekKE0a969WnnXZaw8s+fPhwsX7ZZZcV6xdeeGHN2u7du4vzfvTRR8X6RNRw2CPiXUl/08JeALQRl96AJAg7kARhB5Ig7EAShB1IgltcTwAXXHBBzdqtt95anPess85qat3nnXdesT5nzpyGl71q1api/fzzzy/Wq8vCY9q7d29x3smTJxfrExFbdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IguvsJ4DLL7+8Zm3ZsmVtXffRo0eL9UcffbRmrdS3JC1fvryhnkZE1P5hpA0bNhTnPRFvcWXLDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJuHQtsuUrY0SYhqxcubJYv+2222rWTj755OK8AwMDxfrBgweL9dWrVzc8/9y5c4vzbtmypVifPn16sf7hh7XHG613H/+nn35arPeyiBjzRn627EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBPezTwBTpkwp1k855ZSatT179hTnvf3224v1ffv2Fev1nHPOOTVrK1asKM5bb7jnTz75pFgvfT9hIl9Hb1TdLbvtR2wfsL1j1LRTbW+1/Xb1OK29bQJo1nh24zdIuvK4acslvRAR50p6oXoNoIfVDXtEvCzp0HGTF0ka+Z7lgKTFLe4LQIs1esw+MyJGDuY+kDSz1htt90nqa3A9AFqk6RN0ERGlG1wiol9Sv8SNMEA3NXrpbb/tWZJUPR5oXUsA2qHRsG+WtLR6vlTSU61pB0C71L2f3fZjkhZImi5pv6SfSnpS0q8lzZG0R9L3IuL4k3hjLYvd+AZcfPHFxfq6detq1uqNYV76XXdJuvnmm4v1qVOnFusPP/xwzdrVV19dnPfw4cPF+r333lusr1mzplg/UdW6n73uMXtELKlRuqKpjgB0FF+XBZIg7EAShB1IgrADSRB2IAlucZ0Atm/fXqy/8sorNWv1Lr3VGzZ54cKFxXq9y1tz5swp1kvuvvvuYv2BBx5oeNkZsWUHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSS4zj4BHD16tFg/cuRIw8uePXt2sb5p06Zi3R7zbsovlG6hXr9+fXHeJ598sljHV8OWHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeS4Dr7CaDesMzd9Nxzz9WsrV69ujjve++91+p2UmPLDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJcJ19Apg0aVKxPn/+/Jq1evebN+vZZ58t1q+99tq2rh/jV3fLbvsR2wds7xg1baXtvba3V39XtbdNAM0az278BklXjjF9TUTMrf5qf00KQE+oG/aIeFnSoQ70AqCNmjlBd4vtN6rd/Gm13mS7z/ag7cEm1gWgSY2Gfa2kb0maK2mfpJ/VemNE9EfEvIiY1+C6ALRAQ2GPiP0R8XlEHJP0C0kXtbYtAK3WUNhtzxr18ruSdtR6L4DeUPc6u+3HJC2QNN32+5J+KmmB7bmSQtKQpB+2scf0Nm7cWKxff/31NWul321vhXYvH61TN+wRsWSMyeVf9wfQc/i6LJAEYQeSIOxAEoQdSIKwA0lwi2sH1BsW+aabbirWb7jhhmK9dPlr27ZtxXlff/31Yr1ebzNmzCjW0TvYsgNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAElxn74ArrriiWL/nnnuaWv4dd9xRs/bggw8W5128eHGxXu86+86dO4t19A627EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBNfZW2DBggXF+v3339/U8q+77rpi/fnnn69ZO/3004vz3nXXXQ31NGJoaKip+dE5bNmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAmus7fAwoULi/WpU6cW6y+99FKx/swzzxTrJ510Us3aNddcU5y3Xm+2i/WDBw8W6+gddbfsts+0/VvbO22/ZfvH1fRTbW+1/Xb1OK397QJo1Hh24z+T9C8Rcb6kv5P0I9vnS1ou6YWIOFfSC9VrAD2qbtgjYl9EbKuefyxpl6QzJC2SNFC9bUBS+feNAHTVVzpmt322pG9L+r2kmRGxryp9IGlmjXn6JPU13iKAVhj32XjbX5O0SdJPIuLI6FoMjyw45uiCEdEfEfMiYl5TnQJoyrjCbvskDQf9VxHxeDV5v+1ZVX2WpAPtaRFAK9TdjffwtZf1knZFxM9HlTZLWippVfX4VFs6nACOHTtWrJeGVB5PvXRpTSr/HPR9991XnPfw4cPF+rp164r1tWvXFuvoHeM5Zr9E0j9KetP29mraCg2H/Ne2l0naI+l77WkRQCvUDXtE/E5SrW9WlEc/ANAz+LoskARhB5Ig7EAShB1IgrADSXCLawvMmDGjqfnr3Sa6devWYn3+/PkNr7vekMxPP/10w8tGb2HLDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJcJ29BXbt2tXU/DfeeGOxXu/nnA8dOlSz9tBDDxXnLQ33jBMLW3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSILr7C0wMDBQrE+ePLlYv/POO4v1wcHBYn3z5s01a2vWrCnOizzYsgNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEq43NrjtMyX9UtJMSSGpPyLus71S0j9LGvnR8xUR8VydZZVXBqBpETHmDyCMJ+yzJM2KiG22vy7pNUmLNTwe+x8jYvV4myDsQPvVCvt4xmffJ2lf9fxj27skndHa9gC021c6Zrd9tqRvS/p9NekW22/YfsT2tBrz9NketF3+zieAtqq7G//FG+2vSXpJ0r0R8bjtmZI+1PBx/L9peFf/n+osg914oM0aPmaXJNsnSXpG0paI+PkY9bMlPRMRF9RZDmEH2qxW2Ovuxnv4p03XS9o1OujVibsR35W0o9kmAbTPeM7GXyrpvyW9KelYNXmFpCWS5mp4N35I0g+rk3mlZbFlB9qsqd34ViHsQPs1vBsP4MRA2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSKLTQzZ/KGnPqNfTq2m9qFd769W+JHprVCt7O6tWoaP3s39p5fZgRMzrWgMFvdpbr/Yl0VujOtUbu/FAEoQdSKLbYe/v8vpLerW3Xu1LordGdaS3rh6zA+icbm/ZAXQIYQeS6ErYbV9pe7ftd2wv70YPtdgesv2m7e3dHp+uGkPvgO0do6adanur7berxzHH2OtSbytt760+u+22r+pSb2fa/q3tnbbfsv3janpXP7tCXx353Dp+zG57kqQ/SFoo6X1Jr0paEhE7O9pIDbaHJM2LiK5/AcP230v6o6RfjgytZfvfJR2KiFXVf5TTIuJfe6S3lfqKw3i3qbdaw4z/QF387Fo5/HkjurFlv0jSOxHxbkT8SdJGSYu60EfPi4iXJR06bvIiSQPV8wEN/2PpuBq99YSI2BcR26rnH0saGWa8q59doa+O6EbYz5D03qjX76u3xnsPSb+x/Zrtvm43M4aZo4bZ+kDSzG42M4a6w3h30nHDjPfMZ9fI8OfN4gTdl10aEX8r6R8k/ajaXe1JMXwM1kvXTtdK+paGxwDcJ+ln3WymGmZ8k6SfRMSR0bVufnZj9NWRz60bYd8r6cxRr79RTesJEbG3ejwg6QkNH3b0kv0jI+hWjwe63M8XImJ/RHweEcck/UJd/OyqYcY3SfpVRDxeTe76ZzdWX5363LoR9lclnWv7m7YnS/q+pM1d6ONLbE+pTpzI9hRJ31HvDUW9WdLS6vlSSU91sZc/0yvDeNcaZlxd/uy6Pvx5RHT8T9JVGj4j/7+Sbu9GDzX6+mtJr1d/b3W7N0mPaXi37v80fG5jmaS/kvSCpLclPS/p1B7q7T80PLT3GxoO1qwu9XaphnfR35C0vfq7qtufXaGvjnxufF0WSIITdEAShB1IgrADSRB2IAnCDiRB2IEkCDuQxP8DTjFDHqm/Y2UAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoY7N3Ncqb3g",
        "colab_type": "code",
        "outputId": "dcf15b5d-1985-4e69-b3c6-cdf100573f82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "y = y.reshape(-1,1)\n",
        "onehotencoder = OneHotEncoder() \n",
        "y_onehot = onehotencoder.fit_transform(y).toarray() \n",
        "eps = 43\n",
        "X = X*eps/np.max(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_onehot, test_size=0.25, random_state=42)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GS_ppcb9tuC0",
        "colab_type": "text"
      },
      "source": [
        "Preprocessing done X train has training set while X_test has the validation det. Y is in one hot encoding. X's pixels are scaled from 0-1. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1TAqRufsX4V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#user defined inputs:\n",
        "t_mp =0.02\n",
        "t_ref = 0.001\n",
        "alpha = 7\n",
        "n_w = 0.003\n",
        "n_th = 0.1*n_w\n",
        "beta = 10\n",
        "l = 0.03\n",
        "rho = 0.0002\n",
        "\n",
        "n_in= 784#must be 28*28\n",
        "n_hidden = 200#variable\n",
        "n_out= 10\n",
        "epochs = 100\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bQfPWm3BafU",
        "colab_type": "text"
      },
      "source": [
        "Here m represents the no of synapse. As the it is a fully connected network nno of synapse in ith layer is equal to no of node in i-1 layer. In input layer hash one synapse only.\n",
        "\n",
        "W[i][j] represent the weight of ith neuron of a layer connected to jth neuron of the next layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qdu1H9q9iLZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m_in = 1\n",
        "m_hidden = n_in\n",
        "m_out = n_hidden\n",
        "\n",
        "w_in = [random.uniform(-1*math.sqrt(3/m_in),1*math.sqrt(3/m_in)) for i in range(n_in)]\n",
        "w_hidden = [[random.uniform(-1*math.sqrt(3/m_hidden),1*math.sqrt(3/m_hidden)) for i in range (m_hidden)] for j in range(n_hidden)]\n",
        "w_out = [[random.uniform(-1*math.sqrt(3/m_out),1*math.sqrt(3/m_out)) for i in range(m_out)] for j in range(n_out)]\n",
        "\n",
        "vth_in = [alpha*math.sqrt(3/m_in) for i in range(n_in)]\n",
        "vth_hidden = [alpha*math.sqrt(3/m_hidden) for i in range(n_hidden)]\n",
        "vth_out = [alpha*math.sqrt(3/m_out) for i in range(n_out)]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5j-27qHDEDu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this fundtion takes in the mean and generates the no of spikes in time ms second.\n",
        "# gives the index value when it spikes. if spikes = [10,20,40]\n",
        "\n",
        "def gen_spike(mean,time):#time is in ms\n",
        "  A = [random.uniform(0,1) for i in range(time)]\n",
        "  threshold = mean/time\n",
        "  spikes = []\n",
        "  count = 0 \n",
        "  for i in range(len(A)):\n",
        "    if A[i] < threshold:\n",
        "      spikes.append(i)\n",
        "      # count= count +1\n",
        "  # print(len(spikes))\n",
        "  return spikes\n",
        "# stimulus =A[A<threshold];\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8cBUmM1sM2w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQzhokn_sYVE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRF5v9VRZH63",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# inputs = []\n",
        "# img = 10\n",
        "# print(X_train[17])\n",
        "time = 1000#1 s for each image\n",
        "for img in range(len(X_train)):\n",
        "  inputs = []\n",
        "  \n",
        "  for i in X_train[img]:\n",
        "    inputs.append(gen_spike(int(i),time))# inputs tell me which neurons recieve spike.inputs[k] has input spike times of kth input neuron\n",
        "  # print(len(inputs),spike_time)\n",
        "  # print(len(inputs))\n",
        "  spike_time = [ [] for i in range(time+1)]\n",
        "  for i in range(len(inputs)):\n",
        "    for j in inputs[i]:\n",
        "      # print(j)\n",
        "      spike_time[j].append(i)# at a perticular time j which all neurons spike is given by spike_time[j]\n",
        "  # if len(np.max(spike_time)) >1:\n",
        "  #   for i in spike_time:\n",
        "  #     print(i)\n",
        "  #   break\n",
        "  # print(img,len(spike_time))\n",
        "  for i in spike_time:\n",
        "    if i!= [] and np.max(i) > 784:\n",
        "      print(img)\n",
        "      break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYlZK1x2mDqW",
        "colab_type": "code",
        "outputId": "4b2c0b57-6659-434e-9192-4bb07c89abda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.max((X_train[17]))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G46X3BHCthrh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(X_train[76])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-sAXUn6ZgxO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "in_hidden = [[[] for i in range(m_hidden)] for j in range(n_hidden)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmz9RaDybER4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCDnpsP1TNlE",
        "colab_type": "code",
        "outputId": "705a7f52-bfd8-4889-fca7-f9e754fa3813",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "time = 1000#1 s for each image\n",
        "trianing =1\n",
        "# training = len(X_train)\n",
        "for img in range(trianing):\n",
        "  inputs = []\n",
        "  for i in X_train[img]:\n",
        "    inputs.append(gen_spike(i,time))# inputs tell me which neurons recieve spike.inputs[k] has input spike times of kth input neuron\n",
        "  # print(len(inputs),spike_time)\n",
        "  spike_time = [ [] for i in range(time+1)]\n",
        "  for i in range(len(inputs)):\n",
        "    for j in inputs[i]:\n",
        "      # print(j)\n",
        "      spike_time[j].append(i)\n",
        "\n",
        "\n",
        "# for i in X_train[img]:\n",
        "#   inputs.append( gen_spike(i,time))# inputs tell me which neurons recieve spike.inputs[k] has input spike times of kth input neuron\n",
        "# spike_time = [ [] for i in range(time+1)]\n",
        "# for i in range(len(inputs)):\n",
        "#   for j in inputs[i]:\n",
        "#     spike_time[j].append(i)# at a perticular time j which all neurons spike is given by spike_time[j]\n",
        "\n",
        "\n",
        "  in_hidden = [[[] for i in range(m_hidden)] for j in range(n_hidden)]\n",
        "  #####layer 1\n",
        "\n",
        "  hid_ispikes = [[] for i in range(time+1)]\n",
        "  a_in = [[] for i in range(n_in)]#ouput spike of input layer. a_in[j] has spike time of jth neuron\n",
        "\n",
        "  nin_vmp_t=  [[0,0] for i in range(n_in)]# collects infor mation of jth neuron after last inputspike. vmp and time\n",
        "  pre_spike = 0# time when last ouputspike occured of this layer\n",
        "  for i in range(1,time+1):#1 ms interval \n",
        "    # for i in range(n_in):\n",
        "    next_spike = pre_spike \n",
        "    has_spiked = {}\n",
        "    for j in spike_time[i]:\n",
        "      if j>=len(nin_vmp_t):\n",
        "        print(img,spike_time)\n",
        "      # if last_v [j] == []:# if jth no input spike before:\n",
        "      # #   v_pre = 0\n",
        "      # #   t_pre = 0\n",
        "      # # else:\n",
        "      # #   v_pre = last_v[j][0]\n",
        "      # #   t_pre = last_v[j][1]\n",
        "      delta_t = (pre_spike - i)/1000\n",
        "      # if delta_t < t_ref :\n",
        "      w_dyn = min((delta_t/t_ref)**2,1)\n",
        "      nin_vmp_t[j][0] = nin_vmp_t[j][0]*math.exp( ( i - nin_vmp_t[j][1]) / (1000*t_mp))  + w_dyn*w_in[j]\n",
        "      nin_vmp_t[j][1] = i\n",
        "      if nin_vmp_t[j][0] > vth_in[j] and j not in has_spiked:\n",
        "        nin_vmp_t[j][0] = 0\n",
        "        next_spike = i\n",
        "        a_in[j].append(i)\n",
        "        hid_ispikes[i].append(j)\n",
        "        has_spiked[j] =1\n",
        "    pre_spike = next_spike\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  ###layer 2 now. it has input spike in hid_spike. hid_ispike[i] has neurons of inputlayer that spiked at ith ms.\n",
        "  ##a_in[j] has the time when jth neuron spiked\n",
        "  a_hidden = [[] for i in range(n_hidden)]#ouput spike of hidden layer\n",
        "  out_ispikes = [[] for i in range(time+1)]\n",
        "\n",
        "  pre_spike = 0\n",
        "  hid_vmp_t=  [[0,0] for i in range(n_hidden)]\n",
        "  for i in range(1,time+1):\n",
        "    next_spike = pre_spike\n",
        "    has_spiked = {}\n",
        "    for ispike in hid_ispikes[i]:\n",
        "      for j in range(n_hidden):\n",
        "        #time instant:::::i\n",
        "        #inputspike from ispike\n",
        "        # curr neuron ::::j\n",
        "        delta_t = (pre_spike - i)/1000\n",
        "        w_dyn = min((delta_t/t_ref)**2,1)\n",
        "        hid_vmp_t[j][0] = hid_vmp_t[j][0]*math.exp( ( i - hid_vmp_t[j][1]) / (1000*t_mp))  + w_dyn*w_hidden[j][ispike]\n",
        "        hid_vmp_t[j][1] = i\n",
        "        if hid_vmp_t[j][1]> vth_hidden[j] and j not in has_spiked:\n",
        "          hid_vmp_t[j][0] = 0\n",
        "          next_spike = i\n",
        "          a_hidden[j].append(i)\n",
        "          out_ispikes[i].append(j)\n",
        "          has_spiked[j]= 1\n",
        "    pre_spike = next_spike\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  ###output now. it has input spike in out_ispike. out_ispike[i] has neurons of inputlayer that spiked at ith ms.\n",
        "  ##a_in[j] has the time when jth neuron spiked\n",
        "  a_out = [[] for i in range(n_out)]#ouput spike of ouput layer\n",
        "  pre_spike = 0\n",
        "  out_vmp_t=  [[0,0] for i in range(n_out)]\n",
        "  for i in range(1,time+1):\n",
        "    next_spike = pre_spike\n",
        "    has_spiked = {}\n",
        "    for ispike in out_ispikes[i]:\n",
        "      for j in range(n_out):\n",
        "        #time instant:::::i\n",
        "        #inputspike from ispike\n",
        "        # curr neuron ::::j\n",
        "        delta_t = (pre_spike - i)/1000 \n",
        "        w_dyn = min((delta_t/t_ref)**2,1)\n",
        "        out_vmp_t[j][0] = out_vmp_t[j][0]*math.exp( ( i - out_vmp_t[j][1]) / (1000*t_mp))  + w_dyn*w_out[j][ispike]\n",
        "        out_vmp_t[j][1] = i\n",
        "        if out_vmp_t[j][1]> vth_out[j] and j not in has_spiked  :\n",
        "          out_vmp_t[j][0] = 0\n",
        "          next_spike = i\n",
        "          a_out[j].append(i)\n",
        "          has_spiked[j] =1\n",
        "\n",
        "    pre_spike = next_spike\n",
        "  print(\"done forward prop image\",img)\n"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done forward prop image 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSY4NC9qcjK-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "35c9ae6e-e641-4e72-b0fe-88b856edbf28"
      },
      "source": [
        "\n",
        "\n",
        "####backward propagation.\n",
        "o = [ len(o_spike) for o_spike in a_out]\n",
        "max_spike = np.max(o)\n",
        "o = o/max_spike\n",
        "nze = 0\n",
        "predicted = np.argmax(o)\n",
        "print(\"predicted: \",predicted,\" label: \",np.argmax(y_train[img]) )\n",
        "\n",
        "for i in range(len(o)):\n",
        "  if o[i]-y[i]!= 0:\n",
        "    nze = nze + 1\n",
        "##classification\n",
        "# label = max()\n",
        "\n",
        "g_out = [1/vth_out[i] for i in range(n_out)]\n",
        "g_hidden = [1/vth_hidden[i] for i in range(n_hidden)]\n",
        "g_in = [1/vth_in[i] for i in range(n_in)]\n",
        "\n",
        "nact_in = 0#denotes the number of nodes that spiked at any time at the layer\n",
        "nact_hidden = 0\n",
        "nact_out = 0\n",
        "for i in a_in:\n",
        "  if len(i) >0:\n",
        "    nact_in=nact_in+1\n",
        "for i in a_hidden:\n",
        "  if len(i) >0:\n",
        "    nact_hidden=nact_hidden+1\n",
        "for i in a_out:\n",
        "  if len(i) >0:\n",
        "    nact_out=nact_out+1  \n",
        "\n",
        "gavg_in = math.sqrt(sum([g_in[i]*g_in[i] for i in range(n_in) ]) / nact_in)\n",
        "gavg_hidden = math.sqrt(sum([g_hidden[i]*g_hidden[i] for i in range(n_hidden) ]) / nact_hidden)\n",
        "gavg_out = math.sqrt(sum([g_out[i]*g_out[i] for i in range(n_out) ]) / nact_out)\n",
        "##error calculation\n",
        "\n",
        "#output layer\n",
        "error_out = [(o[i] - y_train[img][i])/nze for i in range(n_out)]\n",
        "loss = sum(error_out[i]*error_out[i] for i in range(n_out))\n",
        "print(\"loss: \",loss)\n",
        "\n",
        "#hidden layer\n",
        "error_hidden = [ 0 for i in range(n_hidden)]\n",
        "for i in range(n_hidden):\n",
        "  pre_fac = (g_hidden[i]/gavg_hidden) * math.sqrt(n_hidden/nact_hidden)\n",
        "  temp = 0.0\n",
        "  for j in range(n_out):\n",
        "    temp+=(error_out[j] * w_out[j][i])\n",
        "  error_hidden[i] =pre_fac* temp\n",
        "\n",
        "#inpulayer\n",
        "error_in = [0 for i in range(n_in)]\n",
        "for i in range(n_in):\n",
        "  pre_fac = (g_in[i]/gavg_in) * math.sqrt(n_in/nact_in)\n",
        "  temp = 0.0\n",
        "  for j in range(n_hidden):\n",
        "    temp+= (error_hidden[j] * w_hidden[j][i])\n",
        "  error_in[i] = pre_fac* temp\n",
        "\n",
        "###Weight and threshold updation\n",
        "n_w_in = [0 for i in range(n_in)]\n",
        "n_w_hidden = [[0 for i in range (m_hidden)] for j in range(n_hidden)]\n",
        "n_w_out = [[ 0 for i in range(m_out)] for j in range(n_out)]\n",
        "\n",
        "#avering of input signals of every neuron\n",
        "for i in range(n_in):\n",
        "  a_in[i] = len(a_in[i])\n",
        "dum = max(a_in)\n",
        "a_in = [a_in[i]/dum for i in range((n_in))]\n",
        "\n",
        "for i in range(n_hidden):\n",
        "  a_hidden[i] = len(a_hidden[i])\n",
        "dum = max(a_hidden)\n",
        "a_hidden = [a_hidden[i]/dum for i in range((n_hidden))]\n",
        "\n",
        "for i in range(n_out):\n",
        "  a_out[i] = len(a_out[i])\n",
        "dum = max(a_out)\n",
        "a_out = [a_out[i]/dum for i in range((n_out))]\n",
        "\n",
        "\n",
        "for i in range(n_in):\n",
        "  inputs[i] = len(inputs[i])\n",
        "dum = max(inputs)\n",
        "inputs = [inputs[i]/dum for i in range((n_in))]\n",
        "\n",
        "#output layer updation\n",
        "\n",
        "\n",
        "\n",
        "for i in range(n_out):\n",
        "  req_fac = beta*l*math.exp(beta * sum([w_out[i][j]* w_out[i][j] - 1 for j in range(n_hidden)  ]))\n",
        "  for j in range(n_hidden):\n",
        "    n_w_out[i][j] = w_out[i][j] - n_w*(math.sqrt(n_out/nact_hidden) *error_out[i] * a_hidden[j]  + req_fac*w_out[i][j])\n",
        "  vth_out[i] = vth_out[i] - n_th* math.sqrt(n_out/(n_hidden*nact_hidden)) *error_out[i]*a_out[i]\n",
        "\n",
        "#hidden layer weight updation\n",
        "\n",
        "for i in range(n_hidden):\n",
        "  req_fac = beta*l*math.exp(beta * sum([w_hidden[i][j]* w_hidden[i][j] - 1 for j in range(n_in)  ]))\n",
        "  for j in range(n_in):\n",
        "    n_w_hidden[i][j] = w_hidden[i][j] - n_w*(math.sqrt(n_hidden/nact_in) *error_hidden[i] * a_in[j]  + req_fac*w_hidden[i][j])\n",
        "  vth_hidden[i] = vth_hidden[i] - n_th* math.sqrt(n_hidden/(n_in*nact_in)) *error_hidden[i]*a_hidden[i]\n",
        "\n",
        "#inputlayer weight updation\n",
        "for i in range(n_in):\n",
        "  # req_fac = beta*l*math.exp(beta *( w_in[i]*w_in[i] -1))\n",
        "  # for j in range(n_in):\n",
        "  n_w_in[i] = w_in[i] - n_w*(1 *error_in[i] * inputs[i] )# + req_fac*w_in[i])\n",
        "  vth_in[i] = vth_in[i] - n_th* math.sqrt(n_in) * error_in[i] * a_in[i]\n",
        "w_in = n_w_in\n",
        "w_hidden = n_w_hidden\n",
        "w_out = n_w_out\n",
        "print(\"done backward prop image\",img)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted:  0  label:  7\n",
            "loss:  0.18367346938775508\n",
            "done backward prop image 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfI-xNfoRrK_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c9f7dd70-3428-4975-d55d-c3e7258270a5"
      },
      "source": [
        "print(len(inputs))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "784\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Bm-nLqje3sP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "a514d5ec-968b-40e7-ca9d-508d02a7511a"
      },
      "source": [
        "print((w_hidden))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XP62rzl3xzkS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#dummy\n",
        "nact_in = 0#denotes the number of nodes that spiked at any time at the layer\n",
        "nact_hidden = 0\n",
        "nact_out = 0\n",
        "for i in a_in:\n",
        "  if len(i) >0:\n",
        "    nact_in=nact_in+1\n",
        "for i in a_hidden:\n",
        "  if len(i) >0:\n",
        "    nact_hidden=nact_hidden+1\n",
        "for i in a_out:\n",
        "  if len(i) >0:\n",
        "    nact_out=nact_out+1  \n",
        "gavg_in = math.sqrt(sum([g_in[i]*g_in[i] for i in range(n_in) ]) / nact_in)\n",
        "\n",
        "\n",
        "###error calculation\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVBZyImWK1BR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c30fe0c6-6b68-413e-b53e-53ae5c58e03f"
      },
      "source": [
        "# print(spike_time[time-1])\n",
        "print(np.max(spike_time))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[737]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZKldaq4egMx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "21ca8d03-0ccc-4c0d-9b3d-4711b1c57a9b"
      },
      "source": [
        "# print(hid_ispikes)\n",
        "# print(out_ispikes)\n",
        "print(len(a_out[2]))\n",
        "print(a_out)\n",
        "print(np.max(spike_time))\n",
        "print(spike_time)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "414\n",
            "[[40, 45, 60, 61, 63, 65, 66, 68, 69, 72, 77, 78, 80, 84, 86, 89, 91, 92, 94, 95, 97, 98, 104, 105, 109, 110, 114, 118, 123, 124, 126, 130, 131, 133, 134, 141, 143, 144, 145, 146, 148, 151, 158, 159, 160, 161, 163, 164, 166, 170, 174, 175, 177, 179, 181, 183, 185, 186, 189, 191, 194, 198, 202, 207, 208, 212, 214, 219, 220, 221, 222, 224, 225, 226, 228, 231, 233, 235, 237, 240, 241, 242, 245, 250, 255, 259, 260, 264, 265, 266, 267, 269, 270, 271, 276, 281, 282, 289, 290, 291, 293, 296, 297, 299, 306, 309, 312, 314, 315, 317, 321, 323, 325, 327, 328, 330, 332, 334, 335, 336, 337, 338, 340, 342, 344, 346, 349, 351, 353, 355, 359, 360, 364, 366, 371, 373, 374, 380, 381, 382, 387, 388, 390, 391, 395, 398, 401, 402, 406, 409, 411, 413, 420, 422, 423, 424, 425, 426, 430, 433, 434, 437, 438, 439, 441, 442, 446, 451, 452, 453, 457, 459, 468, 470, 473, 477, 479, 482, 483, 484, 489, 490, 496, 498, 499, 500, 501, 502, 503, 505, 507, 508, 510, 511, 515, 516, 518, 519, 521, 522, 527, 533, 534, 535, 537, 546, 548, 549, 550, 552, 554, 555, 557, 558, 559, 560, 563, 567, 568, 571, 576, 577, 590, 591, 593, 595, 596, 597, 598, 600, 601, 603, 604, 605, 609, 610, 611, 612, 613, 615, 616, 618, 619, 623, 628, 630, 634, 637, 639, 640, 642, 643, 644, 645, 646, 648, 654, 657, 658, 662, 664, 667, 670, 671, 672, 673, 674, 675, 677, 678, 681, 686, 688, 691, 692, 693, 696, 699, 701, 702, 703, 706, 708, 711, 712, 717, 719, 722, 725, 727, 730, 735, 737, 739, 741, 744, 746, 747, 749, 750, 751, 756, 757, 758, 762, 763, 764, 767, 768, 771, 772, 774, 775, 776, 777, 779, 781, 782, 784, 786, 787, 788, 796, 803, 807, 808, 810, 812, 816, 818, 826, 827, 829, 830, 834, 835, 839, 840, 843, 845, 847, 850, 851, 852, 856, 861, 862, 863, 864, 865, 866, 869, 870, 871, 873, 874, 875, 877, 880, 883, 884, 885, 886, 888, 889, 890, 891, 893, 895, 896, 899, 901, 904, 905, 906, 909, 910, 911, 912, 913, 914, 919, 923, 924, 928, 929, 930, 934, 941, 942, 943, 946, 949, 951, 953, 954, 955, 956, 957, 962, 963, 964, 966, 970, 972, 973, 977, 978, 981, 982, 983, 986, 988, 999], [40, 45, 60, 61, 63, 65, 66, 68, 69, 72, 77, 78, 80, 84, 86, 89, 91, 92, 94, 95, 97, 98, 104, 105, 109, 110, 114, 118, 123, 124, 126, 130, 131, 133, 134, 141, 143, 144, 145, 146, 148, 151, 158, 159, 160, 161, 163, 164, 166, 170, 174, 175, 177, 179, 181, 183, 185, 186, 189, 191, 194, 198, 202, 207, 208, 212, 214, 219, 220, 221, 222, 224, 225, 226, 228, 231, 233, 235, 237, 240, 241, 242, 245, 250, 255, 259, 260, 264, 265, 266, 267, 269, 270, 271, 276, 281, 282, 289, 290, 291, 293, 296, 297, 299, 306, 309, 312, 314, 315, 317, 321, 323, 325, 327, 328, 330, 332, 334, 335, 336, 337, 338, 340, 342, 344, 346, 349, 351, 353, 355, 359, 360, 364, 366, 371, 373, 374, 380, 381, 382, 387, 388, 390, 391, 395, 398, 401, 402, 406, 409, 411, 413, 420, 422, 423, 424, 425, 426, 430, 433, 434, 437, 438, 439, 441, 442, 446, 451, 452, 453, 457, 459, 468, 470, 473, 477, 479, 482, 483, 484, 489, 490, 496, 498, 499, 500, 501, 502, 503, 505, 507, 508, 510, 511, 515, 516, 518, 519, 521, 522, 527, 533, 534, 535, 537, 546, 548, 549, 550, 552, 554, 555, 557, 558, 559, 560, 563, 567, 568, 571, 576, 577, 590, 591, 593, 595, 596, 597, 598, 600, 601, 603, 604, 605, 609, 610, 611, 612, 613, 615, 616, 618, 619, 623, 628, 630, 634, 637, 639, 640, 642, 643, 644, 645, 646, 648, 654, 657, 658, 662, 664, 667, 670, 671, 672, 673, 674, 675, 677, 678, 681, 686, 688, 691, 692, 693, 696, 699, 701, 702, 703, 706, 708, 711, 712, 717, 719, 722, 725, 727, 730, 735, 737, 739, 741, 744, 746, 747, 749, 750, 751, 756, 757, 758, 762, 763, 764, 767, 768, 771, 772, 774, 775, 776, 777, 779, 781, 782, 784, 786, 787, 788, 796, 803, 807, 808, 810, 812, 816, 818, 826, 827, 829, 830, 834, 835, 839, 840, 843, 845, 847, 850, 851, 852, 856, 861, 862, 863, 864, 865, 866, 869, 870, 871, 873, 874, 875, 877, 880, 883, 884, 885, 886, 888, 889, 890, 891, 893, 895, 896, 899, 901, 904, 905, 906, 909, 910, 911, 912, 913, 914, 919, 923, 924, 928, 929, 930, 934, 941, 942, 943, 946, 949, 951, 953, 954, 955, 956, 957, 962, 963, 964, 966, 970, 972, 973, 977, 978, 981, 982, 983, 986, 988, 999], [40, 45, 60, 61, 63, 65, 66, 68, 69, 72, 77, 78, 80, 84, 86, 89, 91, 92, 94, 95, 97, 98, 104, 105, 109, 110, 114, 118, 123, 124, 126, 130, 131, 133, 134, 141, 143, 144, 145, 146, 148, 151, 158, 159, 160, 161, 163, 164, 166, 170, 174, 175, 177, 179, 181, 183, 185, 186, 189, 191, 194, 198, 202, 207, 208, 212, 214, 219, 220, 221, 222, 224, 225, 226, 228, 231, 233, 235, 237, 240, 241, 242, 245, 250, 255, 259, 260, 264, 265, 266, 267, 269, 270, 271, 276, 281, 282, 289, 290, 291, 293, 296, 297, 299, 306, 309, 312, 314, 315, 317, 321, 323, 325, 327, 328, 330, 332, 334, 335, 336, 337, 338, 340, 342, 344, 346, 349, 351, 353, 355, 359, 360, 364, 366, 371, 373, 374, 380, 381, 382, 387, 388, 390, 391, 395, 398, 401, 402, 406, 409, 411, 413, 420, 422, 423, 424, 425, 426, 430, 433, 434, 437, 438, 439, 441, 442, 446, 451, 452, 453, 457, 459, 468, 470, 473, 477, 479, 482, 483, 484, 489, 490, 496, 498, 499, 500, 501, 502, 503, 505, 507, 508, 510, 511, 515, 516, 518, 519, 521, 522, 527, 533, 534, 535, 537, 546, 548, 549, 550, 552, 554, 555, 557, 558, 559, 560, 563, 567, 568, 571, 576, 577, 590, 591, 593, 595, 596, 597, 598, 600, 601, 603, 604, 605, 609, 610, 611, 612, 613, 615, 616, 618, 619, 623, 628, 630, 634, 637, 639, 640, 642, 643, 644, 645, 646, 648, 654, 657, 658, 662, 664, 667, 670, 671, 672, 673, 674, 675, 677, 678, 681, 686, 688, 691, 692, 693, 696, 699, 701, 702, 703, 706, 708, 711, 712, 717, 719, 722, 725, 727, 730, 735, 737, 739, 741, 744, 746, 747, 749, 750, 751, 756, 757, 758, 762, 763, 764, 767, 768, 771, 772, 774, 775, 776, 777, 779, 781, 782, 784, 786, 787, 788, 796, 803, 807, 808, 810, 812, 816, 818, 826, 827, 829, 830, 834, 835, 839, 840, 843, 845, 847, 850, 851, 852, 856, 861, 862, 863, 864, 865, 866, 869, 870, 871, 873, 874, 875, 877, 880, 883, 884, 885, 886, 888, 889, 890, 891, 893, 895, 896, 899, 901, 904, 905, 906, 909, 910, 911, 912, 913, 914, 919, 923, 924, 928, 929, 930, 934, 941, 942, 943, 946, 949, 951, 953, 954, 955, 956, 957, 962, 963, 964, 966, 970, 972, 973, 977, 978, 981, 982, 983, 986, 988, 999], [40, 45, 60, 61, 63, 65, 66, 68, 69, 72, 77, 78, 80, 84, 86, 89, 91, 92, 94, 95, 97, 98, 104, 105, 109, 110, 114, 118, 123, 124, 126, 130, 131, 133, 134, 141, 143, 144, 145, 146, 148, 151, 158, 159, 160, 161, 163, 164, 166, 170, 174, 175, 177, 179, 181, 183, 185, 186, 189, 191, 194, 198, 202, 207, 208, 212, 214, 219, 220, 221, 222, 224, 225, 226, 228, 231, 233, 235, 237, 240, 241, 242, 245, 250, 255, 259, 260, 264, 265, 266, 267, 269, 270, 271, 276, 281, 282, 289, 290, 291, 293, 296, 297, 299, 306, 309, 312, 314, 315, 317, 321, 323, 325, 327, 328, 330, 332, 334, 335, 336, 337, 338, 340, 342, 344, 346, 349, 351, 353, 355, 359, 360, 364, 366, 371, 373, 374, 380, 381, 382, 387, 388, 390, 391, 395, 398, 401, 402, 406, 409, 411, 413, 420, 422, 423, 424, 425, 426, 430, 433, 434, 437, 438, 439, 441, 442, 446, 451, 452, 453, 457, 459, 468, 470, 473, 477, 479, 482, 483, 484, 489, 490, 496, 498, 499, 500, 501, 502, 503, 505, 507, 508, 510, 511, 515, 516, 518, 519, 521, 522, 527, 533, 534, 535, 537, 546, 548, 549, 550, 552, 554, 555, 557, 558, 559, 560, 563, 567, 568, 571, 576, 577, 590, 591, 593, 595, 596, 597, 598, 600, 601, 603, 604, 605, 609, 610, 611, 612, 613, 615, 616, 618, 619, 623, 628, 630, 634, 637, 639, 640, 642, 643, 644, 645, 646, 648, 654, 657, 658, 662, 664, 667, 670, 671, 672, 673, 674, 675, 677, 678, 681, 686, 688, 691, 692, 693, 696, 699, 701, 702, 703, 706, 708, 711, 712, 717, 719, 722, 725, 727, 730, 735, 737, 739, 741, 744, 746, 747, 749, 750, 751, 756, 757, 758, 762, 763, 764, 767, 768, 771, 772, 774, 775, 776, 777, 779, 781, 782, 784, 786, 787, 788, 796, 803, 807, 808, 810, 812, 816, 818, 826, 827, 829, 830, 834, 835, 839, 840, 843, 845, 847, 850, 851, 852, 856, 861, 862, 863, 864, 865, 866, 869, 870, 871, 873, 874, 875, 877, 880, 883, 884, 885, 886, 888, 889, 890, 891, 893, 895, 896, 899, 901, 904, 905, 906, 909, 910, 911, 912, 913, 914, 919, 923, 924, 928, 929, 930, 934, 941, 942, 943, 946, 949, 951, 953, 954, 955, 956, 957, 962, 963, 964, 966, 970, 972, 973, 977, 978, 981, 982, 983, 986, 988, 999], [40, 45, 60, 61, 63, 65, 66, 68, 69, 72, 77, 78, 80, 84, 86, 89, 91, 92, 94, 95, 97, 98, 104, 105, 109, 110, 114, 118, 123, 124, 126, 130, 131, 133, 134, 141, 143, 144, 145, 146, 148, 151, 158, 159, 160, 161, 163, 164, 166, 170, 174, 175, 177, 179, 181, 183, 185, 186, 189, 191, 194, 198, 202, 207, 208, 212, 214, 219, 220, 221, 222, 224, 225, 226, 228, 231, 233, 235, 237, 240, 241, 242, 245, 250, 255, 259, 260, 264, 265, 266, 267, 269, 270, 271, 276, 281, 282, 289, 290, 291, 293, 296, 297, 299, 306, 309, 312, 314, 315, 317, 321, 323, 325, 327, 328, 330, 332, 334, 335, 336, 337, 338, 340, 342, 344, 346, 349, 351, 353, 355, 359, 360, 364, 366, 371, 373, 374, 380, 381, 382, 387, 388, 390, 391, 395, 398, 401, 402, 406, 409, 411, 413, 420, 422, 423, 424, 425, 426, 430, 433, 434, 437, 438, 439, 441, 442, 446, 451, 452, 453, 457, 459, 468, 470, 473, 477, 479, 482, 483, 484, 489, 490, 496, 498, 499, 500, 501, 502, 503, 505, 507, 508, 510, 511, 515, 516, 518, 519, 521, 522, 527, 533, 534, 535, 537, 546, 548, 549, 550, 552, 554, 555, 557, 558, 559, 560, 563, 567, 568, 571, 576, 577, 590, 591, 593, 595, 596, 597, 598, 600, 601, 603, 604, 605, 609, 610, 611, 612, 613, 615, 616, 618, 619, 623, 628, 630, 634, 637, 639, 640, 642, 643, 644, 645, 646, 648, 654, 657, 658, 662, 664, 667, 670, 671, 672, 673, 674, 675, 677, 678, 681, 686, 688, 691, 692, 693, 696, 699, 701, 702, 703, 706, 708, 711, 712, 717, 719, 722, 725, 727, 730, 735, 737, 739, 741, 744, 746, 747, 749, 750, 751, 756, 757, 758, 762, 763, 764, 767, 768, 771, 772, 774, 775, 776, 777, 779, 781, 782, 784, 786, 787, 788, 796, 803, 807, 808, 810, 812, 816, 818, 826, 827, 829, 830, 834, 835, 839, 840, 843, 845, 847, 850, 851, 852, 856, 861, 862, 863, 864, 865, 866, 869, 870, 871, 873, 874, 875, 877, 880, 883, 884, 885, 886, 888, 889, 890, 891, 893, 895, 896, 899, 901, 904, 905, 906, 909, 910, 911, 912, 913, 914, 919, 923, 924, 928, 929, 930, 934, 941, 942, 943, 946, 949, 951, 953, 954, 955, 956, 957, 962, 963, 964, 966, 970, 972, 973, 977, 978, 981, 982, 983, 986, 988, 999], [40, 45, 60, 61, 63, 65, 66, 68, 69, 72, 77, 78, 80, 84, 86, 89, 91, 92, 94, 95, 97, 98, 104, 105, 109, 110, 114, 118, 123, 124, 126, 130, 131, 133, 134, 141, 143, 144, 145, 146, 148, 151, 158, 159, 160, 161, 163, 164, 166, 170, 174, 175, 177, 179, 181, 183, 185, 186, 189, 191, 194, 198, 202, 207, 208, 212, 214, 219, 220, 221, 222, 224, 225, 226, 228, 231, 233, 235, 237, 240, 241, 242, 245, 250, 255, 259, 260, 264, 265, 266, 267, 269, 270, 271, 276, 281, 282, 289, 290, 291, 293, 296, 297, 299, 306, 309, 312, 314, 315, 317, 321, 323, 325, 327, 328, 330, 332, 334, 335, 336, 337, 338, 340, 342, 344, 346, 349, 351, 353, 355, 359, 360, 364, 366, 371, 373, 374, 380, 381, 382, 387, 388, 390, 391, 395, 398, 401, 402, 406, 409, 411, 413, 420, 422, 423, 424, 425, 426, 430, 433, 434, 437, 438, 439, 441, 442, 446, 451, 452, 453, 457, 459, 468, 470, 473, 477, 479, 482, 483, 484, 489, 490, 496, 498, 499, 500, 501, 502, 503, 505, 507, 508, 510, 511, 515, 516, 518, 519, 521, 522, 527, 533, 534, 535, 537, 546, 548, 549, 550, 552, 554, 555, 557, 558, 559, 560, 563, 567, 568, 571, 576, 577, 590, 591, 593, 595, 596, 597, 598, 600, 601, 603, 604, 605, 609, 610, 611, 612, 613, 615, 616, 618, 619, 623, 628, 630, 634, 637, 639, 640, 642, 643, 644, 645, 646, 648, 654, 657, 658, 662, 664, 667, 670, 671, 672, 673, 674, 675, 677, 678, 681, 686, 688, 691, 692, 693, 696, 699, 701, 702, 703, 706, 708, 711, 712, 717, 719, 722, 725, 727, 730, 735, 737, 739, 741, 744, 746, 747, 749, 750, 751, 756, 757, 758, 762, 763, 764, 767, 768, 771, 772, 774, 775, 776, 777, 779, 781, 782, 784, 786, 787, 788, 796, 803, 807, 808, 810, 812, 816, 818, 826, 827, 829, 830, 834, 835, 839, 840, 843, 845, 847, 850, 851, 852, 856, 861, 862, 863, 864, 865, 866, 869, 870, 871, 873, 874, 875, 877, 880, 883, 884, 885, 886, 888, 889, 890, 891, 893, 895, 896, 899, 901, 904, 905, 906, 909, 910, 911, 912, 913, 914, 919, 923, 924, 928, 929, 930, 934, 941, 942, 943, 946, 949, 951, 953, 954, 955, 956, 957, 962, 963, 964, 966, 970, 972, 973, 977, 978, 981, 982, 983, 986, 988, 999], [40, 45, 60, 61, 63, 65, 66, 68, 69, 72, 77, 78, 80, 84, 86, 89, 91, 92, 94, 95, 97, 98, 104, 105, 109, 110, 114, 118, 123, 124, 126, 130, 131, 133, 134, 141, 143, 144, 145, 146, 148, 151, 158, 159, 160, 161, 163, 164, 166, 170, 174, 175, 177, 179, 181, 183, 185, 186, 189, 191, 194, 198, 202, 207, 208, 212, 214, 219, 220, 221, 222, 224, 225, 226, 228, 231, 233, 235, 237, 240, 241, 242, 245, 250, 255, 259, 260, 264, 265, 266, 267, 269, 270, 271, 276, 281, 282, 289, 290, 291, 293, 296, 297, 299, 306, 309, 312, 314, 315, 317, 321, 323, 325, 327, 328, 330, 332, 334, 335, 336, 337, 338, 340, 342, 344, 346, 349, 351, 353, 355, 359, 360, 364, 366, 371, 373, 374, 380, 381, 382, 387, 388, 390, 391, 395, 398, 401, 402, 406, 409, 411, 413, 420, 422, 423, 424, 425, 426, 430, 433, 434, 437, 438, 439, 441, 442, 446, 451, 452, 453, 457, 459, 468, 470, 473, 477, 479, 482, 483, 484, 489, 490, 496, 498, 499, 500, 501, 502, 503, 505, 507, 508, 510, 511, 515, 516, 518, 519, 521, 522, 527, 533, 534, 535, 537, 546, 548, 549, 550, 552, 554, 555, 557, 558, 559, 560, 563, 567, 568, 571, 576, 577, 590, 591, 593, 595, 596, 597, 598, 600, 601, 603, 604, 605, 609, 610, 611, 612, 613, 615, 616, 618, 619, 623, 628, 630, 634, 637, 639, 640, 642, 643, 644, 645, 646, 648, 654, 657, 658, 662, 664, 667, 670, 671, 672, 673, 674, 675, 677, 678, 681, 686, 688, 691, 692, 693, 696, 699, 701, 702, 703, 706, 708, 711, 712, 717, 719, 722, 725, 727, 730, 735, 737, 739, 741, 744, 746, 747, 749, 750, 751, 756, 757, 758, 762, 763, 764, 767, 768, 771, 772, 774, 775, 776, 777, 779, 781, 782, 784, 786, 787, 788, 796, 803, 807, 808, 810, 812, 816, 818, 826, 827, 829, 830, 834, 835, 839, 840, 843, 845, 847, 850, 851, 852, 856, 861, 862, 863, 864, 865, 866, 869, 870, 871, 873, 874, 875, 877, 880, 883, 884, 885, 886, 888, 889, 890, 891, 893, 895, 896, 899, 901, 904, 905, 906, 909, 910, 911, 912, 913, 914, 919, 923, 924, 928, 929, 930, 934, 941, 942, 943, 946, 949, 951, 953, 954, 955, 956, 957, 962, 963, 964, 966, 970, 972, 973, 977, 978, 981, 982, 983, 986, 988, 999], [40, 45, 60, 61, 63, 65, 66, 68, 69, 72, 77, 78, 80, 84, 86, 89, 91, 92, 94, 95, 97, 98, 104, 105, 109, 110, 114, 118, 123, 124, 126, 130, 131, 133, 134, 141, 143, 144, 145, 146, 148, 151, 158, 159, 160, 161, 163, 164, 166, 170, 174, 175, 177, 179, 181, 183, 185, 186, 189, 191, 194, 198, 202, 207, 208, 212, 214, 219, 220, 221, 222, 224, 225, 226, 228, 231, 233, 235, 237, 240, 241, 242, 245, 250, 255, 259, 260, 264, 265, 266, 267, 269, 270, 271, 276, 281, 282, 289, 290, 291, 293, 296, 297, 299, 306, 309, 312, 314, 315, 317, 321, 323, 325, 327, 328, 330, 332, 334, 335, 336, 337, 338, 340, 342, 344, 346, 349, 351, 353, 355, 359, 360, 364, 366, 371, 373, 374, 380, 381, 382, 387, 388, 390, 391, 395, 398, 401, 402, 406, 409, 411, 413, 420, 422, 423, 424, 425, 426, 430, 433, 434, 437, 438, 439, 441, 442, 446, 451, 452, 453, 457, 459, 468, 470, 473, 477, 479, 482, 483, 484, 489, 490, 496, 498, 499, 500, 501, 502, 503, 505, 507, 508, 510, 511, 515, 516, 518, 519, 521, 522, 527, 533, 534, 535, 537, 546, 548, 549, 550, 552, 554, 555, 557, 558, 559, 560, 563, 567, 568, 571, 576, 577, 590, 591, 593, 595, 596, 597, 598, 600, 601, 603, 604, 605, 609, 610, 611, 612, 613, 615, 616, 618, 619, 623, 628, 630, 634, 637, 639, 640, 642, 643, 644, 645, 646, 648, 654, 657, 658, 662, 664, 667, 670, 671, 672, 673, 674, 675, 677, 678, 681, 686, 688, 691, 692, 693, 696, 699, 701, 702, 703, 706, 708, 711, 712, 717, 719, 722, 725, 727, 730, 735, 737, 739, 741, 744, 746, 747, 749, 750, 751, 756, 757, 758, 762, 763, 764, 767, 768, 771, 772, 774, 775, 776, 777, 779, 781, 782, 784, 786, 787, 788, 796, 803, 807, 808, 810, 812, 816, 818, 826, 827, 829, 830, 834, 835, 839, 840, 843, 845, 847, 850, 851, 852, 856, 861, 862, 863, 864, 865, 866, 869, 870, 871, 873, 874, 875, 877, 880, 883, 884, 885, 886, 888, 889, 890, 891, 893, 895, 896, 899, 901, 904, 905, 906, 909, 910, 911, 912, 913, 914, 919, 923, 924, 928, 929, 930, 934, 941, 942, 943, 946, 949, 951, 953, 954, 955, 956, 957, 962, 963, 964, 966, 970, 972, 973, 977, 978, 981, 982, 983, 986, 988, 999], [40, 45, 60, 61, 63, 65, 66, 68, 69, 72, 77, 78, 80, 84, 86, 89, 91, 92, 94, 95, 97, 98, 104, 105, 109, 110, 114, 118, 123, 124, 126, 130, 131, 133, 134, 141, 143, 144, 145, 146, 148, 151, 158, 159, 160, 161, 163, 164, 166, 170, 174, 175, 177, 179, 181, 183, 185, 186, 189, 191, 194, 198, 202, 207, 208, 212, 214, 219, 220, 221, 222, 224, 225, 226, 228, 231, 233, 235, 237, 240, 241, 242, 245, 250, 255, 259, 260, 264, 265, 266, 267, 269, 270, 271, 276, 281, 282, 289, 290, 291, 293, 296, 297, 299, 306, 309, 312, 314, 315, 317, 321, 323, 325, 327, 328, 330, 332, 334, 335, 336, 337, 338, 340, 342, 344, 346, 349, 351, 353, 355, 359, 360, 364, 366, 371, 373, 374, 380, 381, 382, 387, 388, 390, 391, 395, 398, 401, 402, 406, 409, 411, 413, 420, 422, 423, 424, 425, 426, 430, 433, 434, 437, 438, 439, 441, 442, 446, 451, 452, 453, 457, 459, 468, 470, 473, 477, 479, 482, 483, 484, 489, 490, 496, 498, 499, 500, 501, 502, 503, 505, 507, 508, 510, 511, 515, 516, 518, 519, 521, 522, 527, 533, 534, 535, 537, 546, 548, 549, 550, 552, 554, 555, 557, 558, 559, 560, 563, 567, 568, 571, 576, 577, 590, 591, 593, 595, 596, 597, 598, 600, 601, 603, 604, 605, 609, 610, 611, 612, 613, 615, 616, 618, 619, 623, 628, 630, 634, 637, 639, 640, 642, 643, 644, 645, 646, 648, 654, 657, 658, 662, 664, 667, 670, 671, 672, 673, 674, 675, 677, 678, 681, 686, 688, 691, 692, 693, 696, 699, 701, 702, 703, 706, 708, 711, 712, 717, 719, 722, 725, 727, 730, 735, 737, 739, 741, 744, 746, 747, 749, 750, 751, 756, 757, 758, 762, 763, 764, 767, 768, 771, 772, 774, 775, 776, 777, 779, 781, 782, 784, 786, 787, 788, 796, 803, 807, 808, 810, 812, 816, 818, 826, 827, 829, 830, 834, 835, 839, 840, 843, 845, 847, 850, 851, 852, 856, 861, 862, 863, 864, 865, 866, 869, 870, 871, 873, 874, 875, 877, 880, 883, 884, 885, 886, 888, 889, 890, 891, 893, 895, 896, 899, 901, 904, 905, 906, 909, 910, 911, 912, 913, 914, 919, 923, 924, 928, 929, 930, 934, 941, 942, 943, 946, 949, 951, 953, 954, 955, 956, 957, 962, 963, 964, 966, 970, 972, 973, 977, 978, 981, 982, 983, 986, 988, 999], [40, 45, 60, 61, 63, 65, 66, 68, 69, 72, 77, 78, 80, 84, 86, 89, 91, 92, 94, 95, 97, 98, 104, 105, 109, 110, 114, 118, 123, 124, 126, 130, 131, 133, 134, 141, 143, 144, 145, 146, 148, 151, 158, 159, 160, 161, 163, 164, 166, 170, 174, 175, 177, 179, 181, 183, 185, 186, 189, 191, 194, 198, 202, 207, 208, 212, 214, 219, 220, 221, 222, 224, 225, 226, 228, 231, 233, 235, 237, 240, 241, 242, 245, 250, 255, 259, 260, 264, 265, 266, 267, 269, 270, 271, 276, 281, 282, 289, 290, 291, 293, 296, 297, 299, 306, 309, 312, 314, 315, 317, 321, 323, 325, 327, 328, 330, 332, 334, 335, 336, 337, 338, 340, 342, 344, 346, 349, 351, 353, 355, 359, 360, 364, 366, 371, 373, 374, 380, 381, 382, 387, 388, 390, 391, 395, 398, 401, 402, 406, 409, 411, 413, 420, 422, 423, 424, 425, 426, 430, 433, 434, 437, 438, 439, 441, 442, 446, 451, 452, 453, 457, 459, 468, 470, 473, 477, 479, 482, 483, 484, 489, 490, 496, 498, 499, 500, 501, 502, 503, 505, 507, 508, 510, 511, 515, 516, 518, 519, 521, 522, 527, 533, 534, 535, 537, 546, 548, 549, 550, 552, 554, 555, 557, 558, 559, 560, 563, 567, 568, 571, 576, 577, 590, 591, 593, 595, 596, 597, 598, 600, 601, 603, 604, 605, 609, 610, 611, 612, 613, 615, 616, 618, 619, 623, 628, 630, 634, 637, 639, 640, 642, 643, 644, 645, 646, 648, 654, 657, 658, 662, 664, 667, 670, 671, 672, 673, 674, 675, 677, 678, 681, 686, 688, 691, 692, 693, 696, 699, 701, 702, 703, 706, 708, 711, 712, 717, 719, 722, 725, 727, 730, 735, 737, 739, 741, 744, 746, 747, 749, 750, 751, 756, 757, 758, 762, 763, 764, 767, 768, 771, 772, 774, 775, 776, 777, 779, 781, 782, 784, 786, 787, 788, 796, 803, 807, 808, 810, 812, 816, 818, 826, 827, 829, 830, 834, 835, 839, 840, 843, 845, 847, 850, 851, 852, 856, 861, 862, 863, 864, 865, 866, 869, 870, 871, 873, 874, 875, 877, 880, 883, 884, 885, 886, 888, 889, 890, 891, 893, 895, 896, 899, 901, 904, 905, 906, 909, 910, 911, 912, 913, 914, 919, 923, 924, 928, 929, 930, 934, 941, 942, 943, 946, 949, 951, 953, 954, 955, 956, 957, 962, 963, 964, 966, 970, 972, 973, 977, 978, 981, 982, 983, 986, 988, 999]]\n",
            "[737]\n",
            "[[214, 240, 490], [546], [370, 398, 709], [273, 343, 492], [268, 269], [244, 261, 268, 354, 371, 399, 600, 682], [215, 291, 381, 492, 601], [288, 300, 354, 373, 438, 600, 738], [241, 548], [237, 242], [299, 316, 570], [213, 238, 242, 288, 436, 545, 684], [214, 288, 290], [241, 268, 270, 355], [265, 327, 381, 436, 519, 544], [212, 316, 462, 519], [290, 301, 737], [239, 264, 267, 572], [328, 653, 682], [264, 356], [371], [242, 400], [299, 316], [300, 301, 353, 736], [215, 344, 518], [216, 262, 316, 325, 492, 517, 681, 708], [290, 316, 381, 600, 628], [244, 271, 355, 599], [273, 291, 372, 462], [238, 272, 321, 356, 371, 409], [490, 547, 710], [237, 243, 291, 546], [270, 299, 318, 354, 601, 654], [293, 298, 353, 380, 382, 601, 655], [347, 435], [267, 326, 382, 384, 518], [289, 490, 709], [260, 372, 407], [465, 628], [290, 407, 572, 626, 654, 709], [241, 288, 301, 319, 437, 545, 683], [293, 298, 317, 372, 545], [325, 399], [260, 270, 436, 572, 656], [214, 266, 627, 737], [343, 492], [243, 289, 344, 346, 381, 627], [261, 272, 373], [344, 545], [373, 682], [292, 298, 517], [436, 492, 518], [261, 316, 319, 355, 373, 518, 682], [298, 437], [290, 344, 346], [239, 240, 273, 291, 437, 520], [236, 264, 291, 318], [343, 344, 374, 653, 711], [292, 298, 325], [370, 546, 627], [214, 328, 343, 372, 408, 435], [238, 240, 245, 267, 381, 399, 517], [262, 410, 519, 628], [264, 265, 381, 571, 682], [287, 299, 316, 318, 371, 400, 491], [327, 328, 380, 436, 601], [290, 317, 462, 519, 572], [212, 237, 293, 408, 434, 547], [213, 491, 546, 626, 654, 710], [216, 242, 267, 288, 381], [492, 519, 626, 627, 709], [265, 271, 291, 344, 373, 463], [214, 268, 271, 370, 436], [241, 317, 321, 327, 343, 465, 710], [272, 464, 574], [241, 244, 292, 409, 573], [244], [240, 243, 294, 328, 435, 598, 736], [600, 628, 708], [319, 383, 601], [215, 237, 266, 299, 355, 438], [355, 571, 655], [436], [214, 264, 371, 381, 491], [216, 242, 263, 290, 626, 682, 736], [317, 709], [214, 240, 272, 300, 356, 654], [211, 215, 290, 353, 354, 574, 656], [214, 462], [407, 435], [266, 372, 381, 399, 434, 653], [239, 262, 326, 382], [289, 293, 328, 344, 410], [241, 243, 370, 435, 464, 519], [211, 464, 490, 491, 520], [272, 290, 291, 300, 400, 408, 492, 681], [291], [407, 490, 599, 653], [272, 355, 398, 408], [265, 272, 381, 627, 708, 709], [264, 381, 409, 490], [261, 287, 709], [213, 268, 296, 329, 492, 601], [291, 708], [317, 380, 400, 517, 627], [214, 215, 298, 318, 320, 463, 708, 710, 737], [289, 291, 600, 601, 655], [212, 344, 436, 463, 681, 738], [265, 294, 345, 383, 490, 573], [245, 264, 343, 354, 545, 654], [212, 241, 316], [236, 268], [216, 238, 272, 288, 492, 517, 571], [213, 268, 316, 547], [261, 263, 437, 601], [244, 272], [291, 626], [288, 326], [237, 243, 273, 292, 315, 317, 343, 372, 490, 573, 681, 738], [288, 292, 489], [213, 544], [264, 299, 342, 601], [215, 318, 355, 573], [239, 240, 371, 436, 519], [328, 354, 436, 489], [214, 289, 346, 356, 371, 546, 600], [245, 518, 570, 574, 601, 626], [315, 545], [291, 329, 408, 545], [268, 319, 345, 380], [265, 544, 547], [356, 372, 400], [601, 654], [213, 437, 462, 518, 600, 654], [299, 464, 572, 654], [269, 273, 343, 627], [237], [244, 265, 268, 315], [242, 326, 409, 545, 572], [212, 291, 316, 371], [268, 317, 326, 683], [215, 327, 374, 410, 546, 573, 654], [262, 345, 489, 627], [242, 293, 345, 437], [241, 299, 301, 346, 684, 737], [241, 297, 382, 408, 519], [266, 342, 546, 710], [266, 270, 372, 373, 437, 519, 545, 628], [316, 372, 401, 492], [242, 289, 410, 682], [269, 270, 288, 296, 301, 319, 345], [243], [216, 244, 265, 271, 345, 380, 683], [345, 572, 655, 738], [289, 294, 316, 409], [546, 547, 627, 653], [328, 437, 438, 518], [242, 343, 626], [263, 271, 346, 372, 408, 711], [212, 293, 381], [298, 520, 572, 655, 737], [243, 287, 653, 738], [239], [214, 462, 600, 710], [320, 519, 655], [214, 265, 319, 382, 546, 628, 681, 710], [241, 291, 293, 315, 436, 626], [272, 545, 600, 655], [599], [267, 410, 571], [239, 242, 356, 492, 574], [271, 300, 319, 547], [345, 371, 600, 710], [328, 356, 464, 709], [300, 400], [216, 243, 267, 299, 463, 490, 654], [239, 272, 409, 572], [268, 289, 291, 545, 709], [271, 300, 628], [241, 264, 265, 300, 318, 328, 345, 347, 546], [316, 399, 436, 547, 574], [239, 241, 300, 600], [269, 270, 328], [345, 353, 465, 518], [299, 301, 317, 600], [410, 465], [317, 318, 370, 408], [245, 269, 409, 491, 572], [290, 301, 316, 354, 547], [353, 372, 373, 465, 708, 709], [245], [293, 410, 462], [212, 354, 381, 383, 437, 599], [263, 290, 346], [270, 292, 437, 517, 599], [269, 381, 625], [292], [211, 271, 353, 464], [243, 316, 342, 346, 355, 372, 710], [292, 437], [291], [241, 382, 655], [216, 270, 288, 409], [268, 321, 493], [315], [545, 599], [355], [272, 383, 399, 489, 518, 626], [243, 268, 291, 301, 372, 382, 628], [215, 382], [319, 437, 546, 708], [268, 270, 288, 319, 381, 399], [216, 273, 289, 300, 380, 491, 544, 572], [293, 409, 600, 655], [238, 267, 271, 287, 328, 344], [214, 600], [272, 319], [289, 301, 318, 463], [547], [269, 438, 463, 574, 737], [239, 272, 301, 317, 318, 345, 410, 464, 680], [269, 316, 319, 520, 601, 628], [271, 273, 344, 465, 600], [289, 372, 383, 627], [266, 271, 342, 354, 356, 382], [269, 345, 347, 547], [240, 267, 434, 438], [288, 292, 293, 319, 373, 462, 463, 517, 545], [265, 372, 437, 599, 737], [299, 318, 346, 371], [301, 344], [262, 400, 683], [292, 300, 370, 383, 600, 737], [261, 343, 408, 572, 600], [240, 370, 490, 493], [264, 315, 344, 381], [240, 244, 289, 343, 347, 437, 491], [240, 372, 462, 492], [], [244, 265, 301, 354, 400, 737], [213, 216, 371, 573, 600, 655], [241, 290, 293, 436, 682, 737], [410, 600], [272, 316, 320], [293, 490], [216, 272, 371, 599, 654], [287, 289], [243, 293, 299, 300, 325, 343, 383, 490], [214, 271, 320, 356, 710], [342, 490], [244, 272, 289, 298, 355, 380, 437], [264, 269, 272, 292, 301, 400, 411], [265, 266, 272, 463, 573, 737], [], [245, 288, 298, 319, 372, 437], [215, 300, 435, 545], [261, 356], [298, 382, 492], [436, 626], [240, 263, 265, 272, 293, 354, 355, 371, 544], [216, 244, 318, 409, 464, 490], [240, 269, 288, 600], [289, 370, 373, 409, 572, 682], [240, 273, 298, 317, 382], [263, 265, 681, 684], [240, 462, 492], [318, 437, 462, 518, 627], [243, 267, 410, 573, 654], [268, 292], [212, 290, 319, 399, 408, 410, 656], [288, 297, 325, 326, 655], [216, 273, 301, 490, 519, 572], [269, 372, 382, 435], [318], [243, 262, 290, 326, 382], [265, 318, 319, 462, 626], [215, 287, 301, 545], [243, 268, 301, 343, 382, 629], [237, 270, 318, 373, 519, 710], [491], [294, 380, 462, 653], [268, 547, 600], [240, 244, 287, 316, 353, 600, 626], [242, 272, 293, 294, 328, 374, 435, 437, 462, 492, 546], [266, 289, 490, 655], [299, 435, 709], [546], [243, 299, 465], [293, 345, 520, 571], [288, 354, 400, 410], [345, 347, 372, 381, 400, 407, 710], [212, 271, 438, 491, 571, 654], [266, 317, 346, 353, 371, 519, 627], [213, 245, 270, 292, 301, 372, 464], [464], [270, 271, 345, 355, 372, 518, 601], [245, 435, 681, 710, 736, 738], [290, 436, 492, 519], [243, 290, 300, 383, 600], [216, 272, 383, 407, 489, 628], [245, 271, 317, 346], [292, 399, 492, 545], [572, 681], [266, 321, 374, 519, 600, 708], [212, 244, 343, 601], [264], [354, 410, 490, 517, 519, 545, 598], [215, 292, 300, 437, 545], [262, 293, 344, 355, 436], [355, 519, 656, 680], [268, 382, 626], [317, 318], [261, 435], [344, 600], [212, 293, 519, 573, 628], [213, 214, 263, 437, 491, 545], [434, 544], [237, 243, 435, 518, 571], [213, 265, 290, 343], [261, 290, 354], [], [265, 292, 463, 491], [273, 491], [216, 242, 270, 599, 681], [292, 435, 545], [293, 318, 409, 518], [212, 214, 244, 272, 297], [214, 325, 345], [214, 243, 292, 372, 436, 519, 546, 628, 655, 709], [236, 345, 382, 435], [272, 382, 408, 545], [293, 301, 343, 656], [273, 399, 682], [245, 269, 300, 317, 354, 410, 436, 626], [238, 263, 268, 370, 571], [212, 244, 298, 315, 382, 438, 517, 574], [240, 317, 342, 572, 655], [213, 287], [400, 601], [244, 268], [213, 382, 518, 519, 520, 708], [], [215, 240, 265, 266, 371, 372, 400, 654, 708], [318, 381, 434, 492], [243, 408, 683, 737], [266, 491], [267, 326, 462, 628, 710], [215, 316], [242, 245, 300, 571], [262, 270], [273, 409], [272, 490, 545], [240, 262, 571], [215, 240, 326, 356], [242, 267, 408, 462], [289, 315, 519], [301, 315, 627, 682], [241, 287, 288, 354, 384, 517, 519, 545, 708], [344, 437, 573, 601, 680], [291, 299, 354, 373, 435, 628, 737], [239, 272, 381, 601], [239, 601], [408], [243, 265, 354, 355, 370], [245, 269, 273, 289, 301, 464, 546, 681], [267, 326, 371, 599, 682], [211, 244, 269, 298, 328, 346, 463], [244, 267, 681, 737], [245, 370], [239, 382], [215, 273, 372, 382, 574], [264, 684], [261, 315, 318, 655, 680], [215, 243, 268, 289, 319, 328, 356, 520, 626], [399, 407, 437], [383, 490, 655, 738], [288, 381], [262, 399, 573], [318, 346, 490], [243, 288, 315, 654, 709, 737], [214, 320, 354], [245, 463, 465, 599, 626], [238, 263, 345], [241, 517, 573, 598, 709], [288, 462, 680, 737], [627, 655], [398, 407], [301, 345, 399, 490, 518, 572, 708], [241, 243, 261, 293, 399, 463, 680], [243, 273, 317, 653], [492], [215, 243, 262, 266, 342], [262, 464, 546, 574, 710], [270, 288, 316, 346, 355, 407], [269, 301, 492, 519, 543], [241, 271, 316, 656, 683], [656], [215, 462, 464], [240, 372, 710], [212, 238, 263], [342, 343, 409, 546, 681, 737], [242, 263, 268, 300, 435, 545, 573], [264, 326], [213, 268, 300, 371, 493, 655], [291, 370, 435, 517, 520, 572], [263, 382], [213, 271, 408, 490], [269], [262, 268, 291, 292, 299], [398, 409, 436], [273, 491], [267], [212, 267, 268, 328, 465, 572, 681], [301, 346, 570, 599, 627], [216, 298, 319, 327, 492, 545], [244, 264, 316, 320, 344, 408, 435], [296, 382, 490, 518], [270, 292, 317, 371, 600], [268, 571, 708], [655], [271, 545], [318, 709], [273, 318, 400, 547, 738], [239, 261, 264, 266], [265, 289, 320, 370, 436], [266, 407, 626], [241, 244, 263, 269, 270, 343, 408, 517, 601, 709], [382], [325, 546], [240, 318, 544, 626, 655, 710, 736], [216, 328, 371, 380, 490, 545, 625], [319, 326, 371], [263, 293, 327, 491, 573, 654], [216, 288, 321, 374, 544, 681], [273, 293, 371, 438], [245, 326, 408], [547, 628], [463, 464, 709, 710, 711, 737], [271, 372], [239, 292, 299, 318, 492, 655], [266, 346, 437], [212, 238, 318, 708, 738], [270, 410, 437, 626, 655], [244, 264, 343, 437, 546, 626, 628], [214, 319, 327], [], [214, 236, 242, 262, 268, 343, 353, 355, 437, 572, 601, 654], [267, 410, 464, 546, 573], [399, 626], [245, 266, 271, 518, 628], [292, 572, 628, 683], [329, 344, 490, 517, 520, 682], [213, 215, 266, 328, 518], [216, 263, 264, 298, 315, 683], [], [343, 371, 372, 600, 682], [266, 300, 370, 437, 628], [241, 243, 572], [407, 463, 571, 599], [214, 293, 316, 400, 435], [215, 245, 268, 299, 319, 354, 382], [213, 267, 547], [262, 268, 295, 574], [267, 298, 326, 328, 355, 399, 463, 492, 627], [244, 265, 294, 346, 355, 370, 371, 464], [240, 243, 268, 317, 319, 326, 371, 435, 600], [272, 292, 344, 627], [213, 627], [237, 267, 269, 289, 291, 328, 383, 437, 491], [242, 290, 327, 373], [216, 245, 294, 325, 409, 546], [240, 373, 708], [239, 289], [325, 345, 371, 409], [214, 245, 355, 399, 737], [214, 238, 243, 272, 290, 371], [262], [240, 271, 354, 409, 710], [240, 291, 654], [244, 300, 408, 601], [240, 261, 316, 492, 518, 709], [270, 492], [239, 372, 573, 709], [215, 267, 299, 344, 410, 436, 464, 710], [288, 293, 326, 344], [267, 292, 345, 346, 355, 372], [215, 327, 354, 654, 682], [237, 261, 270, 271, 346, 629], [408, 599, 654], [242, 266, 270, 289, 325, 491], [212, 216, 245, 269, 317, 343, 407, 409, 462, 627, 655], [290, 355, 547], [291, 293, 463, 600], [319, 327, 599, 681], [212, 244, 261, 290, 315, 520, 627], [243, 325, 573, 654, 708], [272, 292, 319, 407, 462], [244, 299, 318, 321, 490], [271, 344, 372, 599], [264, 266, 271, 355, 491, 518, 656], [242, 261, 356, 436], [212, 261, 263], [269, 315, 319, 465, 518], [243, 269, 290, 373, 409, 410, 601, 710], [268, 299, 380], [290, 300, 344, 545], [373, 571], [240, 269, 327, 343, 345, 400, 437], [244, 268, 271, 370, 464], [240, 346, 545, 546], [492, 654, 710], [239, 269, 318, 408, 435, 655], [292, 600, 627, 737], [264, 343, 519, 601], [216, 345, 372, 682], [297, 343, 490, 654, 681], [240, 242, 265, 370], [438, 545], [260, 328, 407], [238, 325, 370, 518, 572, 626], [240, 265, 343, 492, 573, 574, 708], [290, 293, 409, 547], [215, 272, 301, 328, 347, 372, 383, 546, 601, 625], [238, 329, 344], [260, 573], [214, 271, 291, 299, 315, 343, 600, 681], [214, 290, 316, 492, 654], [291, 373, 546, 710], [290, 301, 317, 353, 463, 518], [270, 355, 411, 436, 601, 709], [214, 547], [243, 271, 492, 681], [266, 270, 343, 372], [299, 317, 409, 491, 599], [291, 298, 327], [213, 298, 321, 355, 399, 519, 547], [269, 328, 708], [243, 290, 300, 354, 490, 601, 656], [239, 299, 519, 738], [347, 709], [212, 300, 384, 574, 627], [242, 290], [328, 354, 518, 571], [491, 627], [239, 371, 383, 653], [215, 239, 242, 266, 270, 373, 572, 681], [215, 288, 289, 464, 547, 599, 628, 684, 711], [270, 384], [272, 291, 315, 463, 655], [299, 371, 381, 435, 654], [213, 266, 273, 407, 545, 598, 682], [238, 269, 683], [268, 272, 319, 462], [266, 273, 354, 370, 572], [737], [293, 320, 381, 400, 489, 655], [269, 270, 301, 346, 400, 436, 489, 681], [241, 266, 517, 655, 681], [216, 243, 299, 344, 371, 464], [293, 328, 342, 438], [242, 292, 492], [436, 519], [325, 380, 409, 547, 628], [270, 344, 411, 545], [271, 298, 628], [410, 545, 571, 655], [215, 268, 269, 492], [272, 296, 345, 382], [214, 242, 289, 293, 296, 317, 372, 410, 435, 517], [315, 327, 354, 437], [346, 372, 383, 400, 465, 599, 682], [344, 601], [372], [244, 291, 354, 382, 683], [269, 462], [435, 462], [288, 371], [267, 289], [239, 240, 245, 293, 682], [214, 237, 270, 292, 318, 326, 492, 628], [244, 264, 291, 435, 547], [241, 244, 289, 319, 328, 343, 354, 381, 462, 546], [237, 261, 317, 325, 382], [371, 517], [319], [294, 372, 492, 599], [292], [571, 600, 628, 738], [371], [737], [265, 272, 354, 409, 462, 518, 574], [240, 243, 245, 268, 300, 315, 410, 491], [318, 653], [319, 325, 354, 398, 655], [216, 291, 344, 345], [298, 371, 400, 407], [491, 625, 708], [240, 372, 655], [237, 270, 382, 434, 437], [353, 398, 492, 544], [215, 346, 518, 598], [299, 572], [328, 382, 490, 682], [216, 301, 464, 573], [264, 463, 547, 654], [241, 370, 436, 574], [264, 399, 518, 626], [345, 491, 710], [215, 383, 626], [438, 518, 572], [212, 272, 438, 465], [263, 298, 316, 327, 599], [213, 708], [289, 372, 656, 708], [271], [242, 288, 346, 465, 492, 681, 684], [410, 519, 627, 653], [266, 373, 379, 490, 710], [216, 301, 319, 327, 434, 435], [344, 434, 490, 517, 518], [346, 519, 655], [383, 573, 601, 681], [238, 273, 318, 573], [262, 268, 289, 572, 708], [263, 464], [215, 316, 345, 383, 710, 737], [243, 318, 370, 463], [270, 298, 346, 374], [380, 627], [299, 317, 463, 737], [215, 238, 271, 328, 382, 463, 599], [], [261, 269, 290], [273, 463, 626], [320, 345], [215, 272, 296, 344, 373, 654], [263, 316, 379, 573], [215, 241, 263, 291, 383, 437, 462], [345, 355, 463], [239, 243, 289, 298, 328, 491], [264, 269, 342, 345, 371, 654], [270], [215, 239, 272, 299, 318, 372, 383, 401, 518, 572, 653], [245, 264, 268, 269, 289, 490, 518, 654], [316, 327, 356, 409, 436], [216, 241, 244, 245, 265, 270, 409], [245, 271, 290, 598, 710], [400, 655], [273, 292, 435, 545, 682], [291, 354, 519], [383, 462, 711], [216, 261, 270, 328, 356, 653], [245, 264, 266, 343, 600], [319], [315, 399, 463], [299, 546], [264, 267, 270, 289, 410], [328, 517, 654], [271, 326], [214, 292, 299, 373], [269, 272, 290, 517], [244, 270], [272, 290, 601, 738], [244, 290, 297, 571, 653], [267, 271, 381, 489, 655, 738], [240, 241, 270, 327, 355, 572, 599], [244, 325, 489], [293, 346, 737], [493], [245, 269, 273, 328, 546, 572, 601, 654], [318, 346, 399, 438, 654, 655], [373, 408, 492, 709], [214, 240, 298, 354, 409], [216, 263, 290, 291, 343, 374, 462, 573, 627], [293, 343, 353, 370, 490], [214, 270, 292, 320, 627], [214], [272, 287, 297, 438, 464, 625], [243, 317, 355, 436, 489, 491], [299, 326, 491], [211, 262, 300, 320, 343, 346, 682], [269, 319, 354, 356, 490, 547], [299, 464, 490], [], [290, 519, 547], [370, 408, 492], [240, 243, 300, 344, 372], [290, 355, 372, 653], [242, 288, 371, 372, 599, 626], [273, 325, 326, 464, 491, 684], [244, 271, 326, 327, 435, 600], [572, 626], [215, 265, 327, 354, 489, 520, 546], [212, 215, 262, 434, 711], [268, 293, 300, 463, 545], [212, 238, 267, 354, 410, 463, 491, 600, 654], [263, 317, 708], [212, 237, 381, 517], [262, 318], [238, 490], [409, 437, 464], [241, 289, 342, 344, 373, 409], [270, 289, 370, 411, 462, 682], [266, 267, 371, 548, 626, 737], [318], [299, 319], [269, 288, 291, 545], [245, 268, 300], [320, 328, 343, 435, 627], [292, 327, 355], [], [273, 353, 519, 601, 655], [301, 599], [273, 288, 290, 627, 654], [291], [214], [264, 346, 710], [244, 245, 343, 409, 410], [327, 355], [382, 489, 517, 653, 683], [519], [462, 655], [265, 271, 300, 400, 464], [270], [213, 547], [268, 293, 491, 599], [245, 267, 327, 462, 490], [273, 289, 299, 346, 436, 571, 627], [214, 654], [215, 265, 292, 490, 654], [245, 264, 371, 628, 682], [319, 328, 463, 489], [270, 343, 382, 435, 709], [271, 300, 319, 328, 462], [241, 268, 271, 272, 300, 381, 626, 627, 653], [238, 242, 384, 400, 465, 572, 655], [238, 266, 464, 574], [292, 408, 628], [240, 291, 300, 680], [260, 261, 372], [266, 316, 409, 435], [242, 383, 464, 517, 653], [241, 291, 371, 519], [328, 435], [270, 288, 372, 600, 654], [317, 409, 437, 572, 653], [299, 320, 372, 380, 546], [240, 262, 265, 290, 408, 684], [242, 266, 325, 409, 437, 655], [265, 382, 492], [269, 299, 326, 490], [270, 372, 492, 518], [266, 315, 383, 407, 437, 655], [371, 410, 573], [240, 268, 319, 601], [270, 316, 383, 408, 546], [242, 263, 627, 708], [216, 299, 355, 399], [266, 326, 490, 571], [260, 327], [214, 490, 627, 737], [354], [240, 244, 317, 381, 407, 625], [241, 244, 292, 316, 544], [240, 263, 264, 492, 572], [269, 346, 371, 434, 517], [240, 287, 356, 573], [215, 267, 288, 343, 345, 353, 398, 545, 546], [265, 299, 325, 437, 547, 574], [299, 436, 545], [212, 629, 708], [408, 436, 462], [599], [301], [346, 464, 546], [238, 243, 288, 301, 320, 345, 409, 437, 490], [241, 268, 316, 353, 438, 518], [288, 291, 346, 737], [212, 326], [290, 301, 318, 326, 400, 436, 683], [301, 371, 709], [270, 291, 328, 372], [239, 270, 407, 545, 737], [244, 300, 382, 489], [266, 288, 437, 599], [342], [265, 298, 354, 437, 682, 710], [288, 407], [214, 289, 546, 709], [242, 244, 297, 410, 601], [298, 315, 711], [271, 289, 462, 463], [214, 291], [271, 490], [236, 268, 463], [240, 261, 317, 345, 383, 682], [243, 315, 318, 573, 628], [301, 370, 381], [269, 465, 518], [], [290], [318, 383, 710], [272, 273, 382, 409, 711], [343, 383, 435, 464], [382, 464, 710], [240, 269, 545, 628, 656], [600, 655], [245, 325, 371, 409, 410, 463, 682], [241, 243, 263, 265, 273, 317, 345, 436, 710], [292, 517, 600, 708], [270, 326, 381, 465], [270, 493, 656], [492, 709, 736], [300, 492, 546], [266, 382], [374, 519, 709, 736], [291, 356, 399, 407, 435, 628], [269, 398, 517, 519, 546, 629, 737], [241, 273, 288, 411, 462, 463, 653], [288, 299, 316, 346, 655], [268], [288, 381, 572, 681, 737], [261, 384, 654], [289, 462, 708], [238, 261, 263, 266, 293, 371, 398, 491, 518], [239, 300, 653, 655], [268, 437, 464, 490], [262, 300, 317, 327, 436, 654, 682], [245, 269, 273, 371, 438], [215, 241, 242, 291, 315, 572, 681], [213, 300, 318, 346, 489], [238, 299, 399], [215, 288, 382, 681], [213, 216, 381, 492], [214, 241, 242, 264, 316, 400, 490, 545, 654], [244, 267, 384, 519], [546, 682], [211, 291, 317, 318, 544, 545], [238, 239, 518], [243, 315, 383], [345, 399, 572, 709], [371, 383, 399], [261, 262, 271, 354, 372, 373, 409, 463, 628], [325, 520, 599, 655], [245, 267, 270, 300, 318, 354, 544, 573, 627], [263, 372, 382, 517, 627], [399, 736], [342, 373, 520, 738], [212, 240, 243, 262, 371, 518], [215, 243, 268, 291, 410, 573, 709], [238, 273, 383, 546, 574, 601, 709], [265, 267, 327], [266, 294, 346, 381, 628], [212, 261, 271, 299, 344], [262, 266, 301, 325, 382], [518, 656], [298, 344, 355, 371, 436, 546], [243, 265, 371], [239, 261, 268, 290, 318, 346, 382, 399, 409, 545, 653, 655], [214, 545, 653], [216, 242, 344, 655], [265, 292, 326, 373, 518, 572], [271, 290, 316, 318, 410, 462, 546], [327, 345, 371, 464, 492], [216, 242, 289], [572, 682, 738], [213, 241, 244, 300, 490, 710], [240, 298, 327, 344, 463, 598, 710], [272, 297, 599, 626, 709], [215, 343, 345, 374, 464, 682, 709], [269, 288, 371, 518, 654], [408, 519], [265, 273, 571, 574], [262, 288, 315, 398, 400, 627, 708], [215, 318, 343, 380, 399, 519, 546, 628], [263, 321, 398, 627], [300, 627], [239, 287, 291, 381, 654], [262, 318, 327], [491, 492, 681], [261, 291, 373, 383, 434, 518], [239, 289, 318, 326, 399], [345], [319, 321, 327, 435, 464], [238, 266, 288, 316, 736], [399, 490, 517, 571, 656, 681], [240, 241, 289, 327, 573, 600, 626], [238, 328, 409, 546], [372, 517, 519, 653, 710], [265, 272, 373, 681], [354, 400, 572], [241, 737], [215, 241, 264, 437, 599], [301, 379, 381], [215, 241], [370, 682], [273, 320, 655], [271, 710], [237, 371, 381, 628], [436, 680], [211, 238, 299, 317, 436, 682], [213, 265, 271, 294, 320, 372, 408, 628], [346, 656, 710], [], [215, 435, 438], [547, 626, 654], [264, 316, 327, 345, 491], [462, 655], [300, 325, 344, 438, 463, 518, 573], [344, 545, 546], [215, 216, 241, 327, 356, 399, 437, 438, 491, 520], [288, 298, 326, 572], [328, 407, 490, 656, 684], [243, 262, 298, 326, 373, 546], [356, 465, 682], [265, 546], [243, 271, 291], [327, 462], [491, 653], [269, 293, 353, 354, 398, 409, 653, 656], [373, 519], [261, 288, 654], [240, 343, 371, 437, 572, 682], [263, 370, 374, 407, 546, 573, 599, 626], [271, 272, 293, 398, 682], [238, 273, 383], [244, 382, 400, 655], [], [240, 261, 263, 299, 315, 382, 600], [262, 517, 545], [272, 317, 326, 381, 437, 491, 518, 546, 573], [266, 737], [242, 327, 343, 346], [273, 572], [319, 654, 681], [400, 462, 491], [237, 268, 318, 437, 463, 545, 737], [265, 408, 462, 600, 627], [268, 291, 317, 343], [300, 655], [238], [239, 370, 437, 462, 599], [300, 435, 464, 601, 654], [263, 601, 682, 708], [435], [213, 293, 400], [211, 264, 344, 437, 600, 710], [271, 370, 546, 710], [343, 346, 400, 409], [436, 437], [263, 545, 654], [462, 599, 654], [400, 462], [215, 345, 544], [354, 436, 544, 572, 682], [319, 345, 382, 518, 573, 736], [212, 263, 265, 301, 354, 408, 573, 625], [288, 436, 517, 518], [245, 408], [436, 627, 655], [269, 300, 345, 491, 600, 681], [573], [265, 270, 289, 400, 655], [216, 243, 342, 356, 547, 601, 708, 709], [269, 298, 346, 354, 680], [216, 239, 241, 266, 288, 599], [291, 374, 399, 517, 545, 708], [215, 264, 346, 519], [245, 292, 655, 683], [316, 327, 344, 464], [214, 237, 299, 315, 321, 353, 381, 411, 628, 653], [371, 409, 599, 682], [211, 243, 267, 289, 463, 545, 571], [492], [629], [262, 272, 399], [263, 264, 289, 343], [238, 319, 342, 354, 372, 653], [238, 272, 598, 737], [214, 266, 289, 492, 708], [318, 371], [326, 438, 682], [292, 319, 345, 737], [293, 298, 299, 374, 490, 628], [238, 270, 317], [238, 242, 292, 520], [211, 269, 289, 326, 328, 599], [243, 273, 301, 408, 737], [214, 237, 272, 518, 547, 600], [215, 288, 317, 345], [211, 262, 301, 315, 382, 401, 519, 655], [239, 343, 373, 708], [267, 299, 408, 409], [298, 346], [372], [243, 346], [268, 270, 271, 355, 519, 681], [239, 465, 681], [240, 263, 269, 326, 548, 680], [263, 436, 572], []]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}